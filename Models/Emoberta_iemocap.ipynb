{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746c87b3",
   "metadata": {},
   "source": [
    "# EmoBERTa-style RoBERTa on IEMOCAP (6-way)\n",
    "\n",
    "This notebook trains a **RoBERTa** classifier on **IEMOCAP 6-way** labels using an **EmoBERTa-style context string** where the **target utterance is surrounded by exactly two `</s>` tokens**.\n",
    "\n",
    "## What you should add for a GitHub repo\n",
    "- Put your CSVs under `data/` (not `/content/...`) and keep data **out of git** (see `.gitignore`).\n",
    "- Add `requirements.txt` (or `environment.yml`) instead of `!pip install ...`.\n",
    "- Add a `README.md` explaining:\n",
    "  - how to obtain IEMOCAP (license restrictions apply),\n",
    "  - how to create the train/val/test CSVs,\n",
    "  - how to run training and reproduce results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f090df3",
   "metadata": {},
   "source": [
    "## 0. Imports & environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this from a clean environment, install deps once:\n",
    "#   pip install -r requirements.txt\n",
    "#\n",
    "# (In Colab you can alternatively run: !pip install -r requirements.txt)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# Optional: version printout for reproducibility\n",
    "import transformers, datasets\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24408015",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e61b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# CONFIG (IEMOCAP 6-way)\n",
    "# =====================\n",
    "\n",
    "# Project layout (GitHub-friendly): keep data in ./data and outputs in ./outputs\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CSV paths (expected under ./data)\n",
    "TRAIN_CSV = DATA_DIR / \"iemocap_emoberta_train.csv\"\n",
    "VAL_CSV   = DATA_DIR / \"iemocap_emoberta_val.csv\"\n",
    "TEST_CSV  = DATA_DIR / \"iemocap_emoberta_test.csv\"\n",
    "\n",
    "# Column names in your CSVs\n",
    "DIALOG_COL  = \"Dialogue_ID\"\n",
    "UTTID_COL   = \"Utterance_ID\"\n",
    "SPEAKER_COL = \"Speaker\"     # \"F\" / \"M\"\n",
    "TEXT_COL    = \"Utterance\"\n",
    "LABEL_COL   = \"Emotion\"\n",
    "\n",
    "# IEMOCAP 6 emotions\n",
    "LABELS = [\"neutral\", \"frustration\", \"sadness\", \"anger\", \"excited\", \"happiness\"]\n",
    "label2id = {l: i for i, l in enumerate(LABELS)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "\n",
    "# Model\n",
    "MODEL_BASE = \"roberta-base\"\n",
    "\n",
    "# Paper-like constants\n",
    "WEIGHT_DECAY = 0.01\n",
    "EPOCHS = 5\n",
    "WARMUP_RATIO = 0.20\n",
    "LR_SCHED = \"linear\"\n",
    "\n",
    "# Optuna: tune ONLY peak LR\n",
    "N_TRIALS = 5\n",
    "LR_LOW, LR_HIGH = 1e-6, 1e-4\n",
    "\n",
    "# Training defaults\n",
    "MAX_LEN = 512\n",
    "BATCH_TRAIN = 8\n",
    "BATCH_EVAL  = 16\n",
    "GRAD_ACCUM  = 1\n",
    "\n",
    "# Reproducibility / reporting\n",
    "SEED = 42\n",
    "SEEDS_FINAL = [42, 43, 44, 45, 46]\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "print(\"LABELS:\", LABELS)\n",
    "\n",
    "# ==========================================\n",
    "# EmoBERTa-style speaker names (IEMOCAP)\n",
    "# Map \"actor id\" = SesXX + (F/M) -> name.\n",
    "# ==========================================\n",
    "NAME_MAP = {\n",
    "    \"Ses01F\": \"MARY\",      \"Ses02F\": \"PATRICIA\", \"Ses03F\": \"JENNIFER\", \"Ses04F\": \"LINDA\",   \"Ses05F\": \"ELIZABETH\",\n",
    "    \"Ses01M\": \"JAMES\",     \"Ses02M\": \"JOHN\",     \"Ses03M\": \"ROBERT\",   \"Ses04M\": \"MICHAEL\", \"Ses05M\": \"WILLIAM\",\n",
    "}\n",
    "\n",
    "# Quick sanity check (helps avoid confusing FileNotFound errors in GitHub runs)\n",
    "for p in [TRAIN_CSV, VAL_CSV, TEST_CSV]:\n",
    "    if not p.exists():\n",
    "        print(f\"⚠️ Missing file: {p} (put your CSVs under ./data)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f51e41",
   "metadata": {},
   "source": [
    "## 2. Load data and filter labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Load + filter to IEMOCAP-6\n",
    "# ==========================\n",
    "\n",
    "# Map common label variants -> canonical names (helps if your CSV uses abbreviations)\n",
    "LABEL_MAP = {\n",
    "    \"neu\": \"neutral\", \"neutral\": \"neutral\",\n",
    "    \"fru\": \"frustration\", \"frustrated\": \"frustration\", \"frustration\": \"frustration\",\n",
    "    \"sad\": \"sadness\", \"sadness\": \"sadness\",\n",
    "    \"ang\": \"anger\", \"anger\": \"anger\",\n",
    "    \"exc\": \"excited\", \"excited\": \"excited\",\n",
    "    \"hap\": \"happiness\", \"happy\": \"happiness\", \"happiness\": \"happiness\",\n",
    "}\n",
    "\n",
    "def load_and_filter_iemocap6(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load a split CSV and keep only the 6 IEMOCAP labels used in this project.\"\"\"\n",
    "    print(f\"--- Processing {path} ---\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Original shape:\", df.shape)\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "    # Normalize types / casing\n",
    "    df[TEXT_COL] = df[TEXT_COL].astype(str)\n",
    "    df[SPEAKER_COL] = df[SPEAKER_COL].astype(str).str.strip().str.upper()\n",
    "    df[UTTID_COL] = df[UTTID_COL].astype(str)\n",
    "    df[DIALOG_COL] = df[DIALOG_COL].astype(str)\n",
    "\n",
    "    df[LABEL_COL] = (\n",
    "        df[LABEL_COL].astype(str).str.strip().str.lower().replace(LABEL_MAP)\n",
    "    )\n",
    "\n",
    "    # Keep only the 6 labels\n",
    "    df = df[df[LABEL_COL].isin(LABELS)].copy()\n",
    "    print(\"After label filtering:\", df.shape)\n",
    "    print(\"Label counts:\\n\", df[LABEL_COL].value_counts())\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = load_and_filter_iemocap6(TRAIN_CSV)\n",
    "val_df   = load_and_filter_iemocap6(VAL_CSV)\n",
    "test_df  = load_and_filter_iemocap6(TEST_CSV)\n",
    "\n",
    "print(\"Rows:\", len(train_df), len(val_df), len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578bbc2",
   "metadata": {},
   "source": [
    "## 3. Reorder rows into turn order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ecc78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_iemocap_csv(\n",
    "    df: pd.DataFrame,\n",
    "    dialog_col: str = DIALOG_COL,\n",
    "    uttid_col: str = UTTID_COL,\n",
    "    spk_col: str = SPEAKER_COL,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Sort utterances inside each dialogue in true turn order.\n",
    "\n",
    "    Assumes IEMOCAP-style Utterance_ID like `..._F003` or `..._M011`.\n",
    "    Uses the dialogue starter (from Dialogue_ID prefix `SesXXF` / `SesXXM`)\n",
    "    to break ties when two rows share the same numeric turn index.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[dialog_col] = df[dialog_col].astype(str)\n",
    "    df[uttid_col]  = df[uttid_col].astype(str)\n",
    "    df[spk_col]    = df[spk_col].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # numeric index from ..._F003 / ..._M011\n",
    "    df[\"_idx\"] = df[uttid_col].str.extract(r\"_[FM](\\d+)$\")[0].astype(int)\n",
    "\n",
    "    # starter speaker from Dialogue_ID like Ses01F_impro01 or Ses03M_...\n",
    "    df[\"_starter\"] = df[dialog_col].str.extract(r\"^Ses\\d{2}([FM])\")[0].fillna(\"F\").str.upper()\n",
    "    df[\"_prio\"] = (df[spk_col] != df[\"_starter\"]).astype(int)  # 0 for starter, 1 for other\n",
    "\n",
    "    df = df.sort_values([dialog_col, \"_idx\", \"_prio\"]).reset_index(drop=True)\n",
    "    return df.drop(columns=[\"_idx\", \"_starter\", \"_prio\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f479c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = reorder_iemocap_csv(train_df)\n",
    "val_df   = reorder_iemocap_csv(val_df)\n",
    "test_df  = reorder_iemocap_csv(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd78ce5",
   "metadata": {},
   "source": [
    "## 4. Tokenizer, collator, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709089ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(MODEL_BASE, use_fast=True)\n",
    "collator = DataCollatorWithPadding(tokenizer=tok)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compatibility-friendly metrics (works across Trainer versions).\"\"\"\n",
    "    preds, labels = eval_pred\n",
    "    # Some HF versions return a tuple(preds,) for logits\n",
    "    if isinstance(preds, (tuple, list)):\n",
    "        preds = preds[0]\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "    return {\n",
    "        \"acc\": accuracy_score(labels, y_pred),\n",
    "        \"weighted_f1\": f1_score(labels, y_pred, average=\"weighted\"),\n",
    "        \"macro_f1\": f1_score(labels, y_pred, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "print(\"CLS:\", tok.cls_token, tok.cls_token_id, \"SEP:\", tok.sep_token, tok.sep_token_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12508878",
   "metadata": {},
   "source": [
    "## 5. Build EmoBERTa-style context (target `</s>` only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1189e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# TARGET-SEP-ONLY context builder (with SPACES around </s>)\n",
    "#   - EXACTLY two </s>: before and after TARGET\n",
    "#   - NO </s> between past/future utterances\n",
    "#   - Adds spaces so tokenizer sees </s> cleanly (prevents token \"glue\")\n",
    "#   - Target includes speaker name too\n",
    "# ==========================\n",
    "\n",
    "def build_context_dataset_target_sep_only(\n",
    "    df: pd.DataFrame,\n",
    "    tokenizer,\n",
    "    max_length: int = 512,\n",
    "    speaker_caps: bool = True,\n",
    "    debug_n: int = 3,\n",
    "    insert_space_between_utts: bool = True,  # readability WITHOUT adding </s>\n",
    "    include_raw_text: bool = True,\n",
    "    name_map: dict | None = None,\n",
    ") -> Dataset:\n",
    "    \"\"\"Create a HF Dataset with pre-tokenized `input_ids` / `attention_mask` / `labels`.\n",
    "\n",
    "    Context format:\n",
    "        LEFT_CONTEXT + [</s>] + TARGET + [</s>] + RIGHT_CONTEXT\n",
    "\n",
    "    Notes for GitHub:\n",
    "    - Avoid relying on `globals()`; pass `name_map` explicitly (defaults to NAME_MAP).\n",
    "    - Consider moving this function into `src/preprocess.py` so it can be imported by scripts/tests.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    name_map = NAME_MAP if name_map is None else name_map\n",
    "\n",
    "    # -------- normalize --------\n",
    "    df[TEXT_COL] = df[TEXT_COL].astype(str)\n",
    "    df[SPEAKER_COL] = df[SPEAKER_COL].astype(str).str.strip().str.upper()\n",
    "    df[LABEL_COL] = df[LABEL_COL].astype(str).str.strip().str.lower().replace(LABEL_MAP)\n",
    "\n",
    "    # Keep only wanted labels\n",
    "    df = df[df[LABEL_COL].isin(LABELS)].copy()\n",
    "\n",
    "    # -------- ordering (IEMOCAP-style if possible, else numeric) --------\n",
    "    # If Utterance_ID ends with _F003 / _M011, we can get a reliable numeric turn index.\n",
    "    turn_ex = df[UTTID_COL].astype(str).str.extract(r\"_[FM](\\d+)$\")[0]\n",
    "    if turn_ex.notna().all():\n",
    "        df[\"_turn\"] = turn_ex.astype(int)\n",
    "        df[\"_starter\"] = df[DIALOG_COL].astype(str).str.extract(r\"^Ses\\d{2}([FM])\")[0].fillna(\"F\").str.upper()\n",
    "        df[\"_prio\"] = (df[SPEAKER_COL] != df[\"_starter\"]).astype(int)\n",
    "        df = df.sort_values([DIALOG_COL, \"_turn\", \"_prio\"]).reset_index(drop=True)\n",
    "    else:\n",
    "        # Fallback: numeric cast (only if your Utterance_ID is already numeric)\n",
    "        df[UTTID_COL] = pd.to_numeric(df[UTTID_COL], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[DIALOG_COL, UTTID_COL]).copy()\n",
    "        df[UTTID_COL] = df[UTTID_COL].astype(int)\n",
    "        df = df.sort_values([DIALOG_COL, UTTID_COL]).reset_index(drop=True)\n",
    "\n",
    "    # -------- speaker names (EmoBERTa NAME_MAP if possible; else use SPEAKER) --------\n",
    "    # NOTE: session is derived from Dialogue_ID (more robust than from Utterance_ID).\n",
    "    df[\"_session\"] = df[DIALOG_COL].astype(str).str.extract(r\"^(Ses\\d{2})\")[0]\n",
    "    df[\"_actor\"] = (df[\"_session\"].fillna(\"UNK\") + df[SPEAKER_COL])\n",
    "    df[\"_name\"] = df[\"_actor\"].map(name_map).fillna(df[SPEAKER_COL])\n",
    "\n",
    "    if speaker_caps:\n",
    "        df[\"_name\"] = df[\"_name\"].astype(str).str.upper()\n",
    "\n",
    "    cls_id = tokenizer.cls_token_id  # <s>\n",
    "    sep_id = tokenizer.sep_token_id  # </s>\n",
    "\n",
    "    # Reserve CLS only (we're manually building the rest)\n",
    "    max_tokens = max_length - 1\n",
    "\n",
    "    all_input_ids, all_attn, all_labels = [], [], []\n",
    "    all_texts, all_dialog, all_turn = [], [], []\n",
    "\n",
    "    dbg_printed = 0\n",
    "    lengths = []\n",
    "    sep_counts = []\n",
    "\n",
    "    # Precompute encodings with/without leading space:\n",
    "    # - First utterance has no leading space\n",
    "    # - Subsequent utterances get a leading space (if insert_space_between_utts=True)\n",
    "    def enc_no_space(x): return tokenizer.encode(x, add_special_tokens=False)\n",
    "    def enc_with_space(x): return tokenizer.encode(\" \" + x, add_special_tokens=False)\n",
    "\n",
    "    for d_id, g in df.groupby(DIALOG_COL, sort=False):\n",
    "        names = g[\"_name\"].tolist()\n",
    "        utts  = g[TEXT_COL].tolist()\n",
    "        labs  = g[LABEL_COL].tolist()\n",
    "        turns = g[UTTID_COL].tolist()\n",
    "\n",
    "        seg_text = [f\"{nm}: {u}\" for nm, u in zip(names, utts)]\n",
    "        seg_ids0 = [enc_no_space(x) for x in seg_text]\n",
    "        seg_ids1 = [enc_with_space(x) for x in seg_text] if insert_space_between_utts else seg_ids0\n",
    "\n",
    "        n = len(seg_text)\n",
    "\n",
    "        for t in range(n):\n",
    "            target_text = seg_text[t]\n",
    "            target_ids  = seg_ids0[t][:]\n",
    "\n",
    "            # Must fit: [SEP] + target + [SEP]\n",
    "            base = 2 + len(target_ids)\n",
    "            if base > max_tokens:\n",
    "                # Truncate target if it's too long\n",
    "                keep = max(0, max_tokens - 2)\n",
    "                target_ids = target_ids[:keep]\n",
    "                base = 2 + len(target_ids)\n",
    "\n",
    "            left_idxs, right_idxs = [], []\n",
    "            left_len = 0\n",
    "            right_len = 0\n",
    "\n",
    "            # Expand context symmetrically outward (t-1, t+1, t-2, t+2, ...)\n",
    "            i = 0\n",
    "            while True:\n",
    "                changed = False\n",
    "                i += 1\n",
    "\n",
    "                li = t - i\n",
    "                if li >= 0:\n",
    "                    add_len = len(seg_ids0[li]) if len(left_idxs) == 0 else len(seg_ids1[li])\n",
    "                    if base + left_len + add_len + right_len <= max_tokens:\n",
    "                        left_idxs.insert(0, li)\n",
    "                        left_len += add_len\n",
    "                        changed = True\n",
    "\n",
    "                ri = t + i\n",
    "                if ri < n:\n",
    "                    add_len = len(seg_ids0[ri]) if len(right_idxs) == 0 else len(seg_ids1[ri])\n",
    "                    if base + left_len + right_len + add_len <= max_tokens:\n",
    "                        right_idxs.append(ri)\n",
    "                        right_len += add_len\n",
    "                        changed = True\n",
    "\n",
    "                if not changed:\n",
    "                    break\n",
    "                if li < 0 and ri >= n:\n",
    "                    break\n",
    "\n",
    "            # LEFT ids \n",
    "            left_ids = []\n",
    "            for k, idx in enumerate(left_idxs):\n",
    "                left_ids += (seg_ids0[idx] if k == 0 else seg_ids1[idx])\n",
    "\n",
    "            # RIGHT ids \n",
    "            right_ids = []\n",
    "            for k, idx in enumerate(right_idxs):\n",
    "                right_ids += (seg_ids0[idx] if k == 0 else seg_ids1[idx])\n",
    "\n",
    "            # Final seq: LEFT + [SEP] + TARGET + [SEP] + RIGHT\n",
    "            seq_ids = left_ids + [sep_id] + target_ids + [sep_id] + right_ids\n",
    "            seq_ids = seq_ids[:max_tokens]\n",
    "\n",
    "            input_ids = [cls_id] + seq_ids\n",
    "            input_ids = input_ids[:max_length]\n",
    "\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_attn.append([1] * len(input_ids))\n",
    "            all_labels.append(label2id[labs[t]])\n",
    "            all_dialog.append(d_id)\n",
    "            all_turn.append(turns[t])\n",
    "\n",
    "            # Optional raw text (debug / inspection). We keep EXACTLY 2 </s> and add spaces around them.\n",
    "            if include_raw_text:\n",
    "                left_raw  = (\" \".join([seg_text[i] for i in left_idxs]).strip())\n",
    "                right_raw = (\" \".join([seg_text[i] for i in right_idxs]).strip())\n",
    "                raw = f\"<s> {left_raw} </s> {target_text} </s> {right_raw}\".strip()\n",
    "                raw = \" \".join(raw.split())\n",
    "                all_texts.append(raw)\n",
    "\n",
    "            lengths.append(len(input_ids))\n",
    "            sep_counts.append(int(np.sum(np.array(input_ids) == sep_id)))\n",
    "\n",
    "            #\n",
    "            if dbg_printed < debug_n:\n",
    "                print(\"=\" * 90)\n",
    "                print(f\"DEBUG {dbg_printed+1} | dialog={d_id} | target_turn={turns[t]} | label={labs[t]}\")\n",
    "                print(f\"Left utts: {len(left_idxs)} | Right utts: {len(right_idxs)} | SEP count in input_ids: {sep_counts[-1]}\")\n",
    "                if include_raw_text:\n",
    "                    parts = all_texts[-1].split(\"</s>\")\n",
    "                    print(\"\\nRAW split:\")\n",
    "                    print(\"PAST   :\", parts[0].replace(\"<s>\", \"\").strip()[:220])\n",
    "                    print(\"CURRENT:\", (parts[1].strip() if len(parts) > 1 else \"\")[:220])\n",
    "                    print(\"FUTURE :\", (parts[2].strip() if len(parts) > 2 else \"\")[:220])\n",
    "                print(\"\\nDECODED (first 140 tokens):\")\n",
    "                print(tokenizer.decode(input_ids[:140], skip_special_tokens=False))\n",
    "                dbg_printed += 1\n",
    "\n",
    "    print(\"\\nToken length stats:\",\n",
    "          f\"min={int(np.min(lengths))}, mean={float(np.mean(lengths)):.1f}, max={int(np.max(lengths))}, n={len(lengths)}\")\n",
    "    print(\"SEP counts stats:\",\n",
    "          f\"min={int(np.min(sep_counts))}, mean={float(np.mean(sep_counts)):.2f}, max={int(np.max(sep_counts))}\")\n",
    "\n",
    "    data = {\n",
    "        \"dialogue_id\": all_dialog,\n",
    "        \"utterance_id\": all_turn,\n",
    "        \"input_ids\": all_input_ids,\n",
    "        \"attention_mask\": all_attn,\n",
    "        \"labels\": all_labels,\n",
    "    }\n",
    "    if include_raw_text:\n",
    "        data[\"context_text_raw\"] = all_texts\n",
    "\n",
    "    return Dataset.from_dict(data)\n",
    "\n",
    "\n",
    "def save_constructed_csv(ds: Dataset, out_csv: Path, id2label: dict | None = None) -> None:\n",
    "    \"\"\"Save a human-inspectable CSV of the constructed context strings.\"\"\"\n",
    "    d = ds.to_dict()\n",
    "    df_out = pd.DataFrame({\n",
    "        \"dialogue_id\": d[\"dialogue_id\"],\n",
    "        \"utterance_id\": d[\"utterance_id\"],\n",
    "        \"label_id\": d[\"labels\"],\n",
    "        \"label\": [id2label.get(int(x), str(x)) if isinstance(id2label, dict) else str(x) for x in d[\"labels\"]],\n",
    "        \"context_text_raw\": d.get(\"context_text_raw\", [\"\"] * len(d[\"labels\"])),\n",
    "    })\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_out.to_csv(out_csv, index=False)\n",
    "    print(\"✅ Saved:\", out_csv, \"| rows:\", len(df_out))\n",
    "\n",
    "\n",
    "# ----------- BUILD + SAVE -----------\n",
    "train_ds_full = build_context_dataset_target_sep_only(\n",
    "    train_df, tok, max_length=MAX_LEN, speaker_caps=True, debug_n=3,\n",
    "    insert_space_between_utts=True, include_raw_text=True\n",
    ")\n",
    "val_ds_full   = build_context_dataset_target_sep_only(\n",
    "    val_df, tok, max_length=MAX_LEN, speaker_caps=True, debug_n=1,\n",
    "    insert_space_between_utts=True, include_raw_text=True\n",
    ")\n",
    "test_ds_full  = build_context_dataset_target_sep_only(\n",
    "    test_df, tok, max_length=MAX_LEN, speaker_caps=True, debug_n=1,\n",
    "    insert_space_between_utts=True, include_raw_text=True\n",
    ")\n",
    "\n",
    "print(\"Sizes:\", len(train_ds_full), len(val_ds_full), len(test_ds_full))\n",
    "\n",
    "save_constructed_csv(train_ds_full, OUTPUT_DIR / \"train_constructed_targetSEPonly.csv\", id2label=id2label)\n",
    "save_constructed_csv(val_ds_full,   OUTPUT_DIR / \"val_constructed_targetSEPonly.csv\",   id2label=id2label)\n",
    "save_constructed_csv(test_ds_full,  OUTPUT_DIR / \"test_constructed_targetSEPonly.csv\",  id2label=id2label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5714dc35",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter search (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5701e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optuna objective: minimize validation loss by tuning ONLY learning rate.\"\"\"\n",
    "    set_seed(SEED)\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", LR_LOW, LR_HIGH, log=True)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_BASE,\n",
    "        num_labels=len(LABELS),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=str(OUTPUT_DIR / f\"optuna_lr_trial_{trial.number}\"),\n",
    "        evaluation_strategy=\"epoch\",   # NOTE: 'eval_strategy' may break on some HF versions\n",
    "        save_strategy=\"no\",\n",
    "\n",
    "        learning_rate=lr,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_TRAIN,\n",
    "        per_device_eval_batch_size=BATCH_EVAL,\n",
    "        gradient_accumulation_steps=GRAD_ACCUM,\n",
    "\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        warmup_ratio=WARMUP_RATIO,\n",
    "        lr_scheduler_type=LR_SCHED,\n",
    "\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=\"none\",\n",
    "        seed=SEED,\n",
    "        logging_steps=200,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds_full,\n",
    "        eval_dataset=val_ds_full,\n",
    "        data_collator=collator,\n",
    "        tokenizer=tok,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    out = trainer.evaluate(val_ds_full)\n",
    "    return out[\"eval_loss\"]  # minimize cross-entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip for GitHub reproducibility: seed Optuna's sampler\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    ")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "best_lr = study.best_params[\"lr\"]\n",
    "print(\"Best lr:\", best_lr)\n",
    "print(\"Best val loss:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb3635",
   "metadata": {},
   "source": [
    "## 7. Final training across multiple seeds + evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "# ---------- callback: save at end of each epoch ----------\n",
    "class SaveByEpochCallback(TrainerCallback):\n",
    "    \"\"\"Extra per-epoch saving (separate from Trainer's own save_strategy).\"\"\"\n",
    "    def __init__(self, out_root: Path, tokenizer):\n",
    "        self.out_root = Path(out_root)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        model = kwargs[\"model\"]\n",
    "        ep = state.epoch\n",
    "        ep_i = int(round(ep)) if ep is not None else 0\n",
    "\n",
    "        save_dir = self.out_root / f\"epoch_{ep_i:02d}\"\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        model.save_pretrained(save_dir)\n",
    "        self.tokenizer.save_pretrained(save_dir)\n",
    "        print(f\"✅ Saved epoch checkpoint to: {save_dir}\")\n",
    "        return control\n",
    "\n",
    "\n",
    "for seed in SEEDS_FINAL:\n",
    "    print(\"\\n\" + \"=\" * 20, \"SEED\", seed, \"=\" * 20)\n",
    "    set_seed(seed)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_BASE,\n",
    "        num_labels=len(LABELS),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    out_dir = OUTPUT_DIR / f\"roberta_iemocap_final_seed{seed}\"\n",
    "\n",
    "    # Keep epoch checkpoints separate (so Trainer's checkpoint cleanup doesn't delete them)\n",
    "    epoch_root = OUTPUT_DIR / f\"epoch_checkpoints_seed{seed}\"\n",
    "    if epoch_root.exists():\n",
    "        shutil.rmtree(epoch_root)\n",
    "    epoch_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    epoch_saver = SaveByEpochCallback(epoch_root, tok)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=str(out_dir),\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"weighted_f1\",\n",
    "        greater_is_better=True,\n",
    "\n",
    "        learning_rate=best_lr,\n",
    "        # NOTE: You used 7 here originally; consider moving this to config so it's not \"magic\".\n",
    "        num_train_epochs=7,\n",
    "        per_device_train_batch_size=BATCH_TRAIN,\n",
    "        per_device_eval_batch_size=BATCH_EVAL,\n",
    "        gradient_accumulation_steps=GRAD_ACCUM,\n",
    "\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        warmup_ratio=WARMUP_RATIO,\n",
    "        lr_scheduler_type=LR_SCHED,\n",
    "\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=\"none\",\n",
    "        seed=seed,\n",
    "        logging_steps=200,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds_full,\n",
    "        eval_dataset=val_ds_full,\n",
    "        data_collator=collator,\n",
    "        tokenizer=tok,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[epoch_saver],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    best_ckpt = trainer.state.best_model_checkpoint\n",
    "    print(\"Best checkpoint:\", best_ckpt)\n",
    "\n",
    "    # Save clean BEST folder\n",
    "    best_dir = OUTPUT_DIR / f\"roberta_iemocap_final_seed{seed}_BEST\"\n",
    "    if best_dir.exists():\n",
    "        shutil.rmtree(best_dir)\n",
    "    shutil.copytree(best_ckpt, best_dir)\n",
    "    tok.save_pretrained(best_dir)\n",
    "    print(\"Saved BEST folder:\", best_dir)\n",
    "\n",
    "    test_metrics = trainer.evaluate(test_ds_full)\n",
    "    print(\"TEST:\", test_metrics)\n",
    "\n",
    "    rows.append({\n",
    "        \"seed\": seed,\n",
    "        \"best_dir\": str(best_dir),\n",
    "        \"test_acc\": float(test_metrics[\"eval_acc\"]),\n",
    "        \"test_weighted_f1\": float(test_metrics[\"eval_weighted_f1\"]),\n",
    "        \"test_macro_f1\": float(test_metrics[\"eval_macro_f1\"]),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9878a2",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- For GitHub, consider moving **training** into a script (`train.py`) so it can be run headlessly and used in CI.\n",
    "- Keep large model checkpoints out of git (use releases, Hugging Face Hub, or external storage).\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

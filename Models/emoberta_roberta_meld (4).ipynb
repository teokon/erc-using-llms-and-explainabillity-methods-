{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hbiz5Q1UR3ir",
    "outputId": "a950e5e8-90e5-4800-b155-587c0e821014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m151.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 3.0.0 which is incompatible.\n",
      "gradio 5.50.0 requires pandas<3.0,>=1.0, but you have pandas 3.0.0 which is incompatible.\n",
      "dask-cudf-cu12 25.10.0 requires pandas<2.4.0dev0,>=2.0, but you have pandas 3.0.0 which is incompatible.\n",
      "bqplot 0.12.45 requires pandas<3.0.0,>=1.0.0, but you have pandas 3.0.0 which is incompatible.\n",
      "cudf-cu12 25.10.0 requires pandas<2.4.0dev0,>=2.0, but you have pandas 3.0.0 which is incompatible.\n",
      "db-dtypes 1.5.0 requires pandas<3.0.0,>=1.5.3, but you have pandas 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# DistilBERT / BERT / RoBERTa (MELD) fine-tuning\n",
    "# Cell 1: Install/upgrade dependencies (Transformers, Datasets, Optuna, etc.)\n",
    "# Tip: change MODEL_BASE to switch backbone/checkpoint\n",
    "# ==========================\n",
    "\n",
    "!pip -q install -U transformers datasets accelerate scikit-learn pandas optuna\n",
    "\n",
    "import os, random, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, set_seed, DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjb4QYGunh8w",
    "outputId": "3f4ebea4-8387-468f-8739-292af946c388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# DistilBERT / BERT / RoBERTa (MELD) fine-tuning\n",
    "# Cell 2: Setup / utilities\n",
    "# Tip: change MODEL_BASE to switch backbone/checkpoint\n",
    "# ==========================\n",
    "\n",
    "# Paths Meld\n",
    "TRAIN_CSV = \"/content/train_sent_emo.csv\"\n",
    "VAL_CSV   = \"/content/dev_sent_emo.csv\"\n",
    "TEST_CSV  = \"/content/test_sent_emo.csv\"\n",
    "\n",
    "# Columns\n",
    "DIALOG_COL  = \"Dialogue_ID\"\n",
    "UTTID_COL   = \"Utterance_ID\"\n",
    "SPEAKER_COL = \"Speaker\"\n",
    "TEXT_COL    = \"Utterance\"\n",
    "LABEL_COL   = \"Emotion\"\n",
    "\n",
    "# MELD Ekman-7\n",
    "\n",
    "LABELS = [\"neutral\", \"joy\", \"sadness\", \"anger\", \"surprise\", \"fear\",\"disgust\"]\n",
    "label2id = {l:i for i,l in enumerate(LABELS)}\n",
    "id2label = {i:l for l,i in label2id.items()}\n",
    "\n",
    "# Model\n",
    "MODEL_BASE = \"roberta-base\"\n",
    "\n",
    "# Paper constants\n",
    "WEIGHT_DECAY = 0.01         # L2 regularization rate λ\n",
    "EPOCHS = 7                  #  epochs\n",
    "WARMUP_RATIO = 0.20\n",
    "LR_SCHED = \"linear\"\n",
    "\n",
    "# Optuna\n",
    "N_TRIALS = 5\n",
    "LR_LOW, LR_HIGH = 1e-6, 1e-4\n",
    "\n",
    "\n",
    "# Training defaults\n",
    "MAX_LEN = 512\n",
    "BATCH_TRAIN = 8\n",
    "BATCH_EVAL  = 16\n",
    "GRAD_ACCUM  = 1\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LU2BpVvMVk9c",
    "outputId": "9e3a2658-8e84-4261-cb13-71e357582228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 9989 1109 2610\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "#  Load MELD CSVs into pandas DataFrames\n",
    "# ==========================\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(\"Rows:\", len(train_df), len(val_df), len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281,
     "referenced_widgets": [
      "faf1e39242704fc3a43ca749a7b8b375",
      "dad63804654c434fbea3a6673d574fc2",
      "5ff38f1111e64611b074bb7b9ecdfe16",
      "5cf65df0dfd1469f82a45fc6c4569ce2",
      "4bf1de8851ea4526a0eace2de7cb1a22",
      "57892cbdf49845afb3e4c9af1791ff37",
      "9b7d3f0261ba45b4bfae68b48c6ec89b",
      "e22b5ba9843b4e059296ae8584023a57",
      "8265aaadffdf4d57a8acb38097bd9158",
      "091390d1fc724f229f73a54217ebfabe",
      "18475146fcba40e2920b5a0b569e761d",
      "4cdb3f04b0a34eeb93857cadf89f7874",
      "4f719933644d41009facb04d1f38daf8",
      "f56d893685f84473845dfc9c4db5b1c8",
      "6a45997ddcb84cba80cc453d342f6ae2",
      "81f125d7e3d24e7eb3a04420eefb78b8",
      "f1bb0ba913e64532add1c55bea362205",
      "61679ec04f0d486687389d0324e24b3f",
      "61eec4164ab142b99409fad380eb824f",
      "45b146146f304230b88f1dbdc5ae9461",
      "757fa4aaa1684ae5940f434f05819ca1",
      "8f69cba65034425aa7d94f659f7707ea",
      "31aa62dc16554ab0989d1e4809c7d9eb",
      "32f82514615546a49bb0aef7f33180d3",
      "8108b8328b084ab18d865073d22cb9de",
      "9e84b975814f4468af7b08d8c4a2c943",
      "bab11628d3ba41ad88d5ed37b24a9d26",
      "edeef8c9a8c540898fd67b87d3f6c382",
      "533239ef45d5439c9b4ea51153ef55d8",
      "4b283fc597ab4a348ca21e2d813d4c52",
      "9071509d3b21462d9aad45a4b229bd6f",
      "a7d8e0954664464a9c5a0fa0ba8fa389",
      "a5ec8504c44b4fe0a2a63115710b8056",
      "af59c0a38cec4b30af1868bcb454578e",
      "024c7c55d1b14ac18db46dadb9c7c3a6",
      "af0c7b59ac69480491607310b6e36aa1",
      "612c8b14a3eb42019139000e54632b0a",
      "6c6fed7960104954a106c7ec3fa58165",
      "756c3f1ebe07466f96a40c02283ce3ed",
      "570a8a1de7b1475489b0d157d3b3f2fc",
      "28c261301f9043af8899501fbeea972f",
      "8150941fea4b4a08a7fa339164b79b93",
      "94101cb911964424987369056f253a6a",
      "39c9e93fbca146df9989b2cbf4e3e0e2",
      "1bb2e62bc2e445488eab1ee055a65ad4",
      "dccc369a736b45ea8e18c6284836350c",
      "ea413c16a7c74d6aae871072e2cab1f2",
      "39bae3abf66b456e8fb20af7154b999c",
      "2caba47770bf4be2be4837c02ad9c9f9",
      "41961ab8885b498094ce35e54453c729",
      "4b80b0c4e3c049d8b014417fd6a4067d",
      "b28a71feaf644e088d4808e383c69a3c",
      "937605bb287b429c971aef2ca24e57cd",
      "2000e92c5ace40a58e8193764c5c0b30",
      "aad3d3f3afae4bb886f6e0a70b5f055e"
     ]
    },
    "id": "djOStolyVmFw",
    "outputId": "4ec89136-d6b7-4632-f8b0-5be000295865"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf1e39242704fc3a43ca749a7b8b375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdb3f04b0a34eeb93857cadf89f7874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31aa62dc16554ab0989d1e4809c7d9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af59c0a38cec4b30af1868bcb454578e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb2e62bc2e445488eab1ee055a65ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================\n",
    "# \n",
    "#  Load tokenizer/model checkpoint and metrics\n",
    "#\n",
    "# ==========================\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_BASE, use_fast=True, add_prefix_space=True)\n",
    "collator = DataCollatorWithPadding(tokenizer=tok)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, y_true = eval_pred\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"acc\": accuracy_score(y_true, y_pred),\n",
    "        \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
    "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0A6_7SYVnZF",
    "outputId": "5447f146-85d5-40a0-c786-36715fdf0c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s>  THE INTERVIEWER: You must’ve had your hands full. CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.</s>  THE INTERVIEWER: You must’ve had your hands full.  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  </s> THE INTERVIEWER: You must’ve had your hands full. </s>  CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s> THE INTERVIEWER: You must’ve had your hands full.</s>  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 3 | dialog=0 | uttid=2 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. THE INTERVIEWER: You must’ve had your hands full.  </s> CHANDLER: That I did. That I did. </s>  THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  THE INTERVIEWER: You must’ve had your hands full. </s> CHANDLER: That I did. That I did.</s>  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "\n",
      "Token length stats: min=8, mean=221.8, max=510, n=9989\n",
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=sadness\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s>  MONICA: What? </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.</s>  MONICA: What?</s>\n",
      "\n",
      "Token length stats: min=13, mean=212.1, max=416, n=1109\n",
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=surprise\n",
      "RAW strict (repr so you see </s>):\n",
      "\"<s> </s> MARK: Why do all you’re coffee mugs have numbers on the bottom? </s>  RACHEL: Oh. That’s so Monica can keep track. That way if one on them is missing, she can be like, ‘Where’s number 27?!’ RACHEL: Y'know what? </s>\"\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> MARK: Why do all you’re coffee mugs have numbers on the bottom?</s>  RACHEL: Oh. That’s so Monica can keep track. That way if one on them is missing, she can be like, ‘Where’s number 27?!’  RACHEL: Y'know what?</s>\n",
      "\n",
      "Token length stats: min=10, mean=216.7, max=511, n=2610\n",
      "Sizes: 9989 1109 2610\n",
      "✅ Saved: /content/train_constructed_context_targetSpeaker_FIXED.csv | rows: 9989\n",
      "✅ Saved: /content/val_constructed_context_targetSpeaker_FIXED.csv | rows: 1109\n",
      "✅ Saved: /content/test_constructed_context_targetSpeaker_FIXED.csv | rows: 2610\n",
      "-rw-r--r-- 1 root root 1.8M Jan 23 09:11 /content/test_constructed_context_targetSpeaker_FIXED.csv\n",
      "-rw-r--r-- 1 root root 6.7M Jan 23 09:11 /content/train_constructed_context_targetSpeaker_FIXED.csv\n",
      "-rw-r--r-- 1 root root 724K Jan 23 09:11 /content/val_constructed_context_targetSpeaker_FIXED.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "#  Build context-augmented dataset (speaker tags + target-aware formatting)\n",
    "# ==========================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "def build_context_dataset_with_text_target_has_speaker(\n",
    "    df, tokenizer, max_length=512, speaker_caps=True, debug_n=3\n",
    "):\n",
    "    df = df.copy()\n",
    "\n",
    "    # normalize\n",
    "    df[TEXT_COL] = df[TEXT_COL].astype(str)\n",
    "    df[SPEAKER_COL] = df[SPEAKER_COL].astype(str)\n",
    "    df[LABEL_COL] = df[LABEL_COL].astype(str).str.strip().str.lower()\n",
    "\n",
    "    # ordering\n",
    "    df[UTTID_COL] = pd.to_numeric(df[UTTID_COL], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[UTTID_COL]).copy()\n",
    "    df[UTTID_COL] = df[UTTID_COL].astype(int)\n",
    "\n",
    "    df = df[df[LABEL_COL].isin(LABELS)].copy()\n",
    "    df = df.sort_values([DIALOG_COL, UTTID_COL]).reset_index(drop=True)\n",
    "\n",
    "    cls_id = tokenizer.cls_token_id  # <s>\n",
    "    sep_id = tokenizer.sep_token_id  # </s>\n",
    "\n",
    "    #  reserve CLS + final outer </s>\n",
    "    max_tokens = max_length - 2\n",
    "\n",
    "    #  \"space token\" to avoid BPE glue between separately-encoded utterances\n",
    "\n",
    "    space_ids = tokenizer.encode(\" \", add_special_tokens=False)\n",
    "    if len(space_ids) == 0:\n",
    "\n",
    "        space_ids = []\n",
    "\n",
    "    all_input_ids, all_attn, all_labels = [], [], []\n",
    "    all_texts, all_dialog, all_turn = [], [], []\n",
    "\n",
    "    dbg_printed = 0\n",
    "    lengths = []\n",
    "\n",
    "    for d_id, g in df.groupby(DIALOG_COL, sort=False):\n",
    "        speakers = g[SPEAKER_COL].tolist()\n",
    "        utts     = g[TEXT_COL].tolist()\n",
    "        labs     = g[LABEL_COL].tolist()\n",
    "        turns    = g[UTTID_COL].tolist()\n",
    "\n",
    "        if speaker_caps:\n",
    "            speakers = [s.upper() for s in speakers]\n",
    "\n",
    "        # segment text WITH speaker for all\n",
    "        seg_text = [f\"{s}: {u}\" for s, u in zip(speakers, utts)]\n",
    "\n",
    "        # IMPORTANT: encode each segment WITHOUT specials\n",
    "        seg_ids  = [tokenizer.encode(x, add_special_tokens=False) for x in seg_text]\n",
    "        n = len(seg_ids)\n",
    "\n",
    "        for t in range(n):\n",
    "            # target ids (WITH speaker)\n",
    "            target_ids = seg_ids[t][:]\n",
    "\n",
    "            #  make room for the two target-boundary </s> ... </s>\n",
    "            if len(target_ids) + 2 > max_tokens:\n",
    "                target_ids = target_ids[: max(0, max_tokens - 2)]\n",
    "\n",
    "\n",
    "            seq_ids  = [sep_id] + target_ids + [sep_id]\n",
    "            #  spaced separators for raw text\n",
    "            seq_text = \" </s> \" + seg_text[t] + \" </s> \"\n",
    "\n",
    "            left, right = t - 1, t + 1\n",
    "            blocked_left = blocked_right = False\n",
    "\n",
    "            while True:\n",
    "                changed = False\n",
    "\n",
    "                # ---- prepend left  ----\n",
    "                if left >= 0 and not blocked_left:\n",
    "                    cand = seg_ids[left]\n",
    "                    #  add a space between utterances to avoid BPE glue\n",
    "                    need = len(cand) + (len(space_ids) if len(seq_ids) > 0 else 0)\n",
    "\n",
    "                    if len(seq_ids) + need <= max_tokens:\n",
    "                        # cand + space + current\n",
    "                        if space_ids:\n",
    "                            seq_ids  = cand + space_ids + seq_ids\n",
    "                        else:\n",
    "                            seq_ids  = cand + seq_ids\n",
    "                        seq_text = seg_text[left] + \" \" + seq_text\n",
    "                        left -= 1\n",
    "                        changed = True\n",
    "                    else:\n",
    "                        blocked_left = True\n",
    "\n",
    "                # ---- append right WITHOUT adding SEP per utterance ----\n",
    "                if right < n and not blocked_right:\n",
    "                    cand = seg_ids[right]\n",
    "                    need = len(cand) + (len(space_ids) if len(seq_ids) > 0 else 0)\n",
    "\n",
    "                    if len(seq_ids) + need <= max_tokens:\n",
    "                        if space_ids:\n",
    "                            seq_ids  = seq_ids + space_ids + cand\n",
    "                        else:\n",
    "                            seq_ids  = seq_ids + cand\n",
    "                        seq_text = seq_text + \" \" + seg_text[right]\n",
    "                        right += 1\n",
    "                        changed = True\n",
    "                    else:\n",
    "                        blocked_right = True\n",
    "\n",
    "                if not changed:\n",
    "                    break\n",
    "\n",
    "            # outer roberta: <s> ... </s>\n",
    "            input_ids = [cls_id] + seq_ids + [sep_id]\n",
    "            input_ids = input_ids[:max_length]\n",
    "\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_attn.append([1]*len(input_ids))\n",
    "            all_labels.append(label2id[labs[t]])\n",
    "\n",
    "            #  raw text stored WITHOUT outer <s> ... </s> \n",
    "\n",
    "            all_texts.append(\"<s> \" + seq_text.strip() + \" </s>\")\n",
    "            all_dialog.append(d_id)\n",
    "            all_turn.append(turns[t])\n",
    "            lengths.append(len(input_ids))\n",
    "\n",
    "            if dbg_printed < debug_n:\n",
    "                print(\"=\"*80)\n",
    "                print(f\"DEBUG {dbg_printed+1} | dialog={d_id} | uttid={turns[t]} | label={labs[t]}\")\n",
    "                print(\"RAW strict (repr so you see </s>):\")\n",
    "                print(repr(all_texts[-1][:1200]))\n",
    "                print(\"\\nDECODED (first 120 tokens):\")\n",
    "                print(tokenizer.decode(input_ids[:120], skip_special_tokens=False))\n",
    "                dbg_printed += 1\n",
    "\n",
    "    print(\"\\nToken length stats:\",\n",
    "          f\"min={int(np.min(lengths))}, mean={float(np.mean(lengths)):.1f}, max={int(np.max(lengths))}, n={len(lengths)}\")\n",
    "\n",
    "    return Dataset.from_dict({\n",
    "        \"dialogue_id\": all_dialog,\n",
    "        \"utterance_id\": all_turn,\n",
    "        \"context_text_raw\": all_texts,\n",
    "        \"input_ids\": all_input_ids,\n",
    "        \"attention_mask\": all_attn,\n",
    "        \"labels\": all_labels\n",
    "    })\n",
    "\n",
    "\n",
    "def save_constructed_csv(ds, out_csv, id2label=None):\n",
    "    d = ds.to_dict()\n",
    "    df_out = pd.DataFrame({\n",
    "        \"dialogue_id\": d[\"dialogue_id\"],\n",
    "        \"utterance_id\": d[\"utterance_id\"],\n",
    "        \"label_id\": d[\"labels\"],\n",
    "        \"label\": [id2label.get(int(x), str(x)) if isinstance(id2label, dict) else str(x) for x in d[\"labels\"]],\n",
    "        \"context_text_raw\": d[\"context_text_raw\"],\n",
    "    })\n",
    "    df_out.to_csv(out_csv, index=False)\n",
    "    print(\"✅ Saved:\", out_csv, \"| rows:\", len(df_out))\n",
    "\n",
    "\n",
    "# ----------- BUILD (prints debug examples) -----------\n",
    "train_ds_full = build_context_dataset_with_text_target_has_speaker(train_df, tok, max_length=MAX_LEN, speaker_caps=True, debug_n=3)\n",
    "val_ds_full   = build_context_dataset_with_text_target_has_speaker(val_df,   tok, max_length=MAX_LEN, speaker_caps=True, debug_n=1)\n",
    "test_ds_full  = build_context_dataset_with_text_target_has_speaker(test_df,  tok, max_length=MAX_LEN, speaker_caps=True, debug_n=1)\n",
    "\n",
    "print(\"Sizes:\", len(train_ds_full), len(val_ds_full), len(test_ds_full))\n",
    "\n",
    "# ----------- SAVE CSV locally  -----------\n",
    "save_constructed_csv(train_ds_full, \"/content/train_constructed_context_targetSpeaker_FIXED.csv\", id2label=id2label)\n",
    "save_constructed_csv(val_ds_full,   \"/content/val_constructed_context_targetSpeaker_FIXED.csv\",   id2label=id2label)\n",
    "save_constructed_csv(test_ds_full,  \"/content/test_constructed_context_targetSpeaker_FIXED.csv\",  id2label=id2label)\n",
    "\n",
    "!ls -lh /content/*_targetSpeaker_FIXED.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kt5VOR64JU02",
    "outputId": "ee2ee37e-195e-4e1e-ceda-8632c049ca65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s></s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.</s>  THE INTERVIEWER: You must’ve had your hands full.  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "len(input_ids): 251\n",
      "len(attn): 251\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "#  Quick sanity check: inspect one processed example\n",
    "# ==========================\n",
    "\n",
    "# pick one example from your built dataset\n",
    "ex = train_ds_full[0]\n",
    "ids = ex[\"input_ids\"]\n",
    "\n",
    "print(tok.decode(ids[:120], skip_special_tokens=False))\n",
    "\n",
    "print(\"len(input_ids):\", len(ex[\"input_ids\"]))\n",
    "print(\"len(attn):\", len(ex[\"attention_mask\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-j_7EHLELHb",
    "outputId": "009a6ad2-ad33-45a4-c8b3-b37fb6c85d51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 9989 val size: 1109\n",
      "fingerprints:\n",
      " train: 4b66420845d37c79b9976e672c085ea8\n",
      " val  : 5efe931aa1e609b7e07f746750e30cdb\n",
      "\n",
      "DECODE sample 0 (first 200 tokens):\n",
      "<s></s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.</s>  THE INTERVIEWER: You must’ve had your hands full.  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties.  CHANDLER: I see.  THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them.  CHANDLER: Good to know.  THE INTERVIEWER: We can go into detail  CHANDLER: No don’t I beg of you!  THE INTERVIEWER: All right then, we\n",
      "\n",
      "Label id dist (sample): {np.int64(0): np.int64(2380), np.int64(1): np.int64(829), np.int64(2): np.int64(330), np.int64(3): np.int64(549), np.int64(4): np.int64(626), np.int64(5): np.int64(146), np.int64(6): np.int64(140)}\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "#  Dataset sanity checks: fingerprints, decode sample, label distribution\n",
    "# ==========================\n",
    "\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "def ds_fingerprint(ds, n=50):\n",
    "    m = hashlib.md5()\n",
    "    for i in range(min(n, len(ds))):\n",
    "        m.update((\",\".join(map(str, ds[i][\"input_ids\"]))).encode())\n",
    "        m.update(str(ds[i][\"labels\"]).encode())\n",
    "    return m.hexdigest()\n",
    "\n",
    "print(\"train size:\", len(train_ds_full), \"val size:\", len(val_ds_full))\n",
    "print(\"fingerprints:\")\n",
    "print(\" train:\", ds_fingerprint(train_ds_full))\n",
    "print(\" val  :\", ds_fingerprint(val_ds_full))\n",
    "\n",
    "# quick decode sanity\n",
    "print(\"\\nDECODE sample 0 (first 200 tokens):\")\n",
    "print(tok.decode(train_ds_full[0][\"input_ids\"][:200], skip_special_tokens=False))\n",
    "\n",
    "# label distribution sanity (first 5k for speed)\n",
    "y = [train_ds_full[i][\"labels\"] for i in range(min(len(train_ds_full), 5000))]\n",
    "print(\"\\nLabel id dist (sample):\", dict(zip(*np.unique(y, return_counts=True))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko_ESSMWcSLq"
   },
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# train/evaluate\n",
    "# ==========================\n",
    "\n",
    "def objective(trial):\n",
    "    set_seed(SEED)\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True)\n",
    "\n",
    "    max_len = 512\n",
    "    batch_train = 8\n",
    "    batch_eval  = 16\n",
    "    grad_acc    = 1\n",
    "\n",
    "    train_ds = build_context_dataset_with_text_target_has_speaker(train_df, tok, max_length=max_len, speaker_caps=True)\n",
    "    val_ds   = build_context_dataset_with_text_target_has_speaker(val_df,   tok, max_length=max_len, speaker_caps=True)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_BASE,\n",
    "        num_labels=len(LABELS),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"optuna_lr_trial_{trial.number}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "\n",
    "        learning_rate=lr,\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=batch_train,\n",
    "        per_device_eval_batch_size=batch_eval,\n",
    "        gradient_accumulation_steps=grad_acc,\n",
    "\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.20,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=\"none\",\n",
    "        seed=SEED,\n",
    "        logging_steps=200,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        data_collator=collator,\n",
    "        tokenizer=tok,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    out = trainer.evaluate(val_ds)\n",
    "\n",
    "    #  minimize cross-entropy loss on validation\n",
    "    return out[\"eval_loss\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "12c45d70257f4647a21fb1a51dc0a90a",
      "fef464bdfd9f4ad68d97dd714f82c328",
      "c23891fcb08f433f8acafaaee957efb0",
      "14d6a26a70e04608a2685c317accc608",
      "1f33c90480484145a80dc1caa885022c",
      "f749a57a41f34a529b77682f177a57fe",
      "acf8464c1723416ea7ab4e7a1526e643",
      "f91c79f430a74d2c894d902bbedc1a5f",
      "8ecbe5d79181457089ee06b05b6c05bc",
      "b02213cce5654490b50d3c3c19c6dbd1",
      "be5d681511aa404ba87cfa1348b40745"
     ]
    },
    "id": "JFwuqlRGqFbx",
    "outputId": "98a10c80-af55-4c3f-92f7-adcbacead7ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 09:12:29,744] A new study created in memory with name: no-name-87a306b8-29b0-44f4-983c-c6052c50bd63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s>  THE INTERVIEWER: You must’ve had your hands full. CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.</s>  THE INTERVIEWER: You must’ve had your hands full.  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  </s> THE INTERVIEWER: You must’ve had your hands full. </s>  CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s> THE INTERVIEWER: You must’ve had your hands full.</s>  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 3 | dialog=0 | uttid=2 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. THE INTERVIEWER: You must’ve had your hands full.  </s> CHANDLER: That I did. That I did. </s>  THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  THE INTERVIEWER: You must’ve had your hands full. </s> CHANDLER: That I did. That I did.</s>  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "\n",
      "Token length stats: min=8, mean=221.8, max=510, n=9989\n",
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=sadness\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s>  MONICA: What? </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.</s>  MONICA: What?</s>\n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=surprise\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.  </s> MONICA: What? </s> </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s> MONICA: What?</s></s>\n",
      "================================================================================\n",
      "DEBUG 3 | dialog=1 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source. </s>  CHANDLER: You’re a genius! JOEY: Aww, man, now we won’t be bank buddies! CHANDLER: Now, there’s two reasons. PHOEBE: Hey. ALL: Hey! PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him. RACHEL: Where?! PHOEBE: On the touchy. ROSS: And PHOEBE: No, I know! PHOEBE: I-I’m sorry, but the moment I touch him, I just wanna throw out my old oath and take a new, dirty one. MONICA: Well, next time your massaging him, you should try and distract yourself. JOEY: Yeah! Yeah! Yeah! Like-like when I’m doing something exciting and I don’t wanna get CHANDLER: Thank you, Joey. JOEY: No-no, thank you. </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source.</s>  CHANDLER: You’re a genius!  JOEY: Aww, man, now we won’t be bank buddies!  CHANDLER: Now, there’s two reasons.  PHOEBE: Hey.  ALL: Hey!  PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him.  RACHEL: Where?!  PHOEBE\n",
      "\n",
      "Token length stats: min=13, mean=212.1, max=416, n=1109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c45d70257f4647a21fb1a51dc0a90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-758279856.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6245' max='6245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6245/6245 05:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.554700</td>\n",
       "      <td>1.640659</td>\n",
       "      <td>0.423805</td>\n",
       "      <td>0.252297</td>\n",
       "      <td>0.085045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.469300</td>\n",
       "      <td>1.535491</td>\n",
       "      <td>0.431921</td>\n",
       "      <td>0.314046</td>\n",
       "      <td>0.143602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.409500</td>\n",
       "      <td>1.461454</td>\n",
       "      <td>0.464382</td>\n",
       "      <td>0.353277</td>\n",
       "      <td>0.174149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.245800</td>\n",
       "      <td>1.278754</td>\n",
       "      <td>0.576195</td>\n",
       "      <td>0.524128</td>\n",
       "      <td>0.321245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.178400</td>\n",
       "      <td>1.251752</td>\n",
       "      <td>0.586114</td>\n",
       "      <td>0.540996</td>\n",
       "      <td>0.340493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 09:17:40,542] Trial 0 finished with value: 1.2517520189285278 and parameters: {'lr': 1.5312186697729886e-06}. Best is trial 0 with value: 1.2517520189285278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s>  THE INTERVIEWER: You must’ve had your hands full. CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.</s>  THE INTERVIEWER: You must’ve had your hands full.  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  </s> THE INTERVIEWER: You must’ve had your hands full. </s>  CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s> THE INTERVIEWER: You must’ve had your hands full.</s>  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 3 | dialog=0 | uttid=2 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. THE INTERVIEWER: You must’ve had your hands full.  </s> CHANDLER: That I did. That I did. </s>  THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  THE INTERVIEWER: You must’ve had your hands full. </s> CHANDLER: That I did. That I did.</s>  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "\n",
      "Token length stats: min=8, mean=221.8, max=510, n=9989\n",
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=sadness\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s>  MONICA: What? </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.</s>  MONICA: What?</s>\n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=surprise\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.  </s> MONICA: What? </s> </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s> MONICA: What?</s></s>\n",
      "================================================================================\n",
      "DEBUG 3 | dialog=1 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source. </s>  CHANDLER: You’re a genius! JOEY: Aww, man, now we won’t be bank buddies! CHANDLER: Now, there’s two reasons. PHOEBE: Hey. ALL: Hey! PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him. RACHEL: Where?! PHOEBE: On the touchy. ROSS: And PHOEBE: No, I know! PHOEBE: I-I’m sorry, but the moment I touch him, I just wanna throw out my old oath and take a new, dirty one. MONICA: Well, next time your massaging him, you should try and distract yourself. JOEY: Yeah! Yeah! Yeah! Like-like when I’m doing something exciting and I don’t wanna get CHANDLER: Thank you, Joey. JOEY: No-no, thank you. </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source.</s>  CHANDLER: You’re a genius!  JOEY: Aww, man, now we won’t be bank buddies!  CHANDLER: Now, there’s two reasons.  PHOEBE: Hey.  ALL: Hey!  PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him.  RACHEL: Where?!  PHOEBE\n",
      "\n",
      "Token length stats: min=13, mean=212.1, max=416, n=1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-758279856.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6245' max='6245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6245/6245 05:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.319600</td>\n",
       "      <td>1.236257</td>\n",
       "      <td>0.607755</td>\n",
       "      <td>0.563275</td>\n",
       "      <td>0.363794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.050400</td>\n",
       "      <td>1.106281</td>\n",
       "      <td>0.624887</td>\n",
       "      <td>0.586076</td>\n",
       "      <td>0.387270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.869900</td>\n",
       "      <td>1.114065</td>\n",
       "      <td>0.636610</td>\n",
       "      <td>0.613577</td>\n",
       "      <td>0.481096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.683300</td>\n",
       "      <td>1.190071</td>\n",
       "      <td>0.635708</td>\n",
       "      <td>0.621456</td>\n",
       "      <td>0.461181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.508900</td>\n",
       "      <td>1.263965</td>\n",
       "      <td>0.639315</td>\n",
       "      <td>0.625062</td>\n",
       "      <td>0.486822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 09:22:48,749] Trial 1 finished with value: 1.263965129852295 and parameters: {'lr': 1.3788900683869114e-05}. Best is trial 0 with value: 1.2517520189285278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s>  THE INTERVIEWER: You must’ve had your hands full. CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.</s>  THE INTERVIEWER: You must’ve had your hands full.  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  </s> THE INTERVIEWER: You must’ve had your hands full. </s>  CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s> THE INTERVIEWER: You must’ve had your hands full.</s>  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 3 | dialog=0 | uttid=2 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. THE INTERVIEWER: You must’ve had your hands full.  </s> CHANDLER: That I did. That I did. </s>  THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  THE INTERVIEWER: You must’ve had your hands full. </s> CHANDLER: That I did. That I did.</s>  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "\n",
      "Token length stats: min=8, mean=221.8, max=510, n=9989\n",
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=sadness\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s>  MONICA: What? </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.</s>  MONICA: What?</s>\n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=surprise\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.  </s> MONICA: What? </s> </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s> MONICA: What?</s></s>\n",
      "================================================================================\n",
      "DEBUG 3 | dialog=1 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source. </s>  CHANDLER: You’re a genius! JOEY: Aww, man, now we won’t be bank buddies! CHANDLER: Now, there’s two reasons. PHOEBE: Hey. ALL: Hey! PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him. RACHEL: Where?! PHOEBE: On the touchy. ROSS: And PHOEBE: No, I know! PHOEBE: I-I’m sorry, but the moment I touch him, I just wanna throw out my old oath and take a new, dirty one. MONICA: Well, next time your massaging him, you should try and distract yourself. JOEY: Yeah! Yeah! Yeah! Like-like when I’m doing something exciting and I don’t wanna get CHANDLER: Thank you, Joey. JOEY: No-no, thank you. </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source.</s>  CHANDLER: You’re a genius!  JOEY: Aww, man, now we won’t be bank buddies!  CHANDLER: Now, there’s two reasons.  PHOEBE: Hey.  ALL: Hey!  PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him.  RACHEL: Where?!  PHOEBE\n",
      "\n",
      "Token length stats: min=13, mean=212.1, max=416, n=1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-758279856.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6245' max='6245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6245/6245 05:04, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>1.379438</td>\n",
       "      <td>0.532011</td>\n",
       "      <td>0.462909</td>\n",
       "      <td>0.270739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.547600</td>\n",
       "      <td>1.630486</td>\n",
       "      <td>0.423805</td>\n",
       "      <td>0.252297</td>\n",
       "      <td>0.085045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.557800</td>\n",
       "      <td>1.661020</td>\n",
       "      <td>0.423805</td>\n",
       "      <td>0.252297</td>\n",
       "      <td>0.085045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.526400</td>\n",
       "      <td>1.653820</td>\n",
       "      <td>0.423805</td>\n",
       "      <td>0.252297</td>\n",
       "      <td>0.085045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.535900</td>\n",
       "      <td>1.641410</td>\n",
       "      <td>0.423805</td>\n",
       "      <td>0.252297</td>\n",
       "      <td>0.085045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 09:27:58,076] Trial 2 finished with value: 1.6414096355438232 and parameters: {'lr': 6.457999908802166e-05}. Best is trial 0 with value: 1.2517520189285278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s>  THE INTERVIEWER: You must’ve had your hands full. CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.</s>  THE INTERVIEWER: You must’ve had your hands full.  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  </s> THE INTERVIEWER: You must’ve had your hands full. </s>  CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s> THE INTERVIEWER: You must’ve had your hands full.</s>  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 3 | dialog=0 | uttid=2 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. THE INTERVIEWER: You must’ve had your hands full.  </s> CHANDLER: That I did. That I did. </s>  THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  THE INTERVIEWER: You must’ve had your hands full. </s> CHANDLER: That I did. That I did.</s>  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "\n",
      "Token length stats: min=8, mean=221.8, max=510, n=9989\n",
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=sadness\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s>  MONICA: What? </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.</s>  MONICA: What?</s>\n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=surprise\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.  </s> MONICA: What? </s> </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s> MONICA: What?</s></s>\n",
      "================================================================================\n",
      "DEBUG 3 | dialog=1 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source. </s>  CHANDLER: You’re a genius! JOEY: Aww, man, now we won’t be bank buddies! CHANDLER: Now, there’s two reasons. PHOEBE: Hey. ALL: Hey! PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him. RACHEL: Where?! PHOEBE: On the touchy. ROSS: And PHOEBE: No, I know! PHOEBE: I-I’m sorry, but the moment I touch him, I just wanna throw out my old oath and take a new, dirty one. MONICA: Well, next time your massaging him, you should try and distract yourself. JOEY: Yeah! Yeah! Yeah! Like-like when I’m doing something exciting and I don’t wanna get CHANDLER: Thank you, Joey. JOEY: No-no, thank you. </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source.</s>  CHANDLER: You’re a genius!  JOEY: Aww, man, now we won’t be bank buddies!  CHANDLER: Now, there’s two reasons.  PHOEBE: Hey.  ALL: Hey!  PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him.  RACHEL: Where?!  PHOEBE\n",
      "\n",
      "Token length stats: min=13, mean=212.1, max=416, n=1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-758279856.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6245' max='6245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6245/6245 05:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.508000</td>\n",
       "      <td>1.514349</td>\n",
       "      <td>0.431019</td>\n",
       "      <td>0.281988</td>\n",
       "      <td>0.112236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.116500</td>\n",
       "      <td>1.179013</td>\n",
       "      <td>0.593327</td>\n",
       "      <td>0.555245</td>\n",
       "      <td>0.357777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.001400</td>\n",
       "      <td>1.134028</td>\n",
       "      <td>0.623986</td>\n",
       "      <td>0.586823</td>\n",
       "      <td>0.393217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>1.150208</td>\n",
       "      <td>0.633003</td>\n",
       "      <td>0.602186</td>\n",
       "      <td>0.406559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>1.140484</td>\n",
       "      <td>0.629396</td>\n",
       "      <td>0.598562</td>\n",
       "      <td>0.404150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 09:33:06,681] Trial 3 finished with value: 1.140484094619751 and parameters: {'lr': 5.482717813019306e-06}. Best is trial 3 with value: 1.140484094619751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s>  THE INTERVIEWER: You must’ve had your hands full. CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.</s>  THE INTERVIEWER: You must’ve had your hands full.  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  </s> THE INTERVIEWER: You must’ve had your hands full. </s>  CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s> THE INTERVIEWER: You must’ve had your hands full.</s>  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 3 | dialog=0 | uttid=2 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. THE INTERVIEWER: You must’ve had your hands full.  </s> CHANDLER: That I did. That I did. </s>  THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  THE INTERVIEWER: You must’ve had your hands full. </s> CHANDLER: That I did. That I did.</s>  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "\n",
      "Token length stats: min=8, mean=221.8, max=510, n=9989\n",
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=sadness\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s>  MONICA: What? </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.</s>  MONICA: What?</s>\n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=surprise\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.  </s> MONICA: What? </s> </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s> MONICA: What?</s></s>\n",
      "================================================================================\n",
      "DEBUG 3 | dialog=1 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source. </s>  CHANDLER: You’re a genius! JOEY: Aww, man, now we won’t be bank buddies! CHANDLER: Now, there’s two reasons. PHOEBE: Hey. ALL: Hey! PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him. RACHEL: Where?! PHOEBE: On the touchy. ROSS: And PHOEBE: No, I know! PHOEBE: I-I’m sorry, but the moment I touch him, I just wanna throw out my old oath and take a new, dirty one. MONICA: Well, next time your massaging him, you should try and distract yourself. JOEY: Yeah! Yeah! Yeah! Like-like when I’m doing something exciting and I don’t wanna get CHANDLER: Thank you, Joey. JOEY: No-no, thank you. </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source.</s>  CHANDLER: You’re a genius!  JOEY: Aww, man, now we won’t be bank buddies!  CHANDLER: Now, there’s two reasons.  PHOEBE: Hey.  ALL: Hey!  PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him.  RACHEL: Where?!  PHOEBE\n",
      "\n",
      "Token length stats: min=13, mean=212.1, max=416, n=1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-758279856.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6245' max='6245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6245/6245 05:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.224300</td>\n",
       "      <td>1.289075</td>\n",
       "      <td>0.590622</td>\n",
       "      <td>0.543027</td>\n",
       "      <td>0.345750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.146700</td>\n",
       "      <td>1.203003</td>\n",
       "      <td>0.606853</td>\n",
       "      <td>0.565600</td>\n",
       "      <td>0.371433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.960500</td>\n",
       "      <td>1.243413</td>\n",
       "      <td>0.616772</td>\n",
       "      <td>0.583316</td>\n",
       "      <td>0.452064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.723400</td>\n",
       "      <td>1.410203</td>\n",
       "      <td>0.593327</td>\n",
       "      <td>0.575008</td>\n",
       "      <td>0.414874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.477600</td>\n",
       "      <td>1.599689</td>\n",
       "      <td>0.619477</td>\n",
       "      <td>0.602965</td>\n",
       "      <td>0.444816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 09:38:14,768] Trial 4 finished with value: 1.5996887683868408 and parameters: {'lr': 4.9607717817852516e-05}. Best is trial 3 with value: 1.140484094619751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lr: 5.482717813019306e-06\n",
      "Best val loss: 1.140484094619751\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Run Optuna study and select best hyperparameters\n",
    "# ==========================\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "print(\"Best lr:\", study.best_params[\"lr\"])\n",
    "print(\"Best val loss:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Qh6kXGaEVtuE",
    "outputId": "a5446524-ac73-4483-bbe6-ce559331b72b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s>  THE INTERVIEWER: You must’ve had your hands full. CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.</s>  THE INTERVIEWER: You must’ve had your hands full.  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  </s> THE INTERVIEWER: You must’ve had your hands full. </s>  CHANDLER: That I did. That I did. THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. </s> THE INTERVIEWER: You must’ve had your hands full.</s>  CHANDLER: That I did. That I did.  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "================================================================================\n",
      "DEBUG 3 | dialog=0 | uttid=2 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system. THE INTERVIEWER: You must’ve had your hands full.  </s> CHANDLER: That I did. That I did. </s>  THE INTERVIEWER: So let’s talk a little bit about your duties. CHANDLER: My duties?  All right. THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. CHANDLER: I see. THE INTERVIEWER: But there’ll be perhaps 30 people under you so you can dump a certain amount on them. CHANDLER: Good to know. THE INTERVIEWER: We can go into detail CHANDLER: No don’t I beg of you! THE INTERVIEWER: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here. CHANDLER: Really?! THE INTERVIEWER: Absolutely.  You can relax </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> CHANDLER: also I was the point person on my company’s transition from the KL-5 to GR-6 system.  THE INTERVIEWER: You must’ve had your hands full. </s> CHANDLER: That I did. That I did.</s>  THE INTERVIEWER: So let’s talk a little bit about your duties.  CHANDLER: My duties?  All right.  THE INTERVIEWER: Now you’ll be heading a whole division, so you’ll have a lot of duties. \n",
      "\n",
      "Token length stats: min=8, mean=221.8, max=510, n=9989\n",
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=sadness\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s>  MONICA: What? </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.</s>  MONICA: What?</s>\n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=surprise\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it.  </s> MONICA: What? </s> </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> PHOEBE: Oh my God, he’s lost it. He’s totally lost it. </s> MONICA: What?</s></s>\n",
      "================================================================================\n",
      "DEBUG 3 | dialog=1 | uttid=0 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "'<s> </s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source. </s>  CHANDLER: You’re a genius! JOEY: Aww, man, now we won’t be bank buddies! CHANDLER: Now, there’s two reasons. PHOEBE: Hey. ALL: Hey! PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him. RACHEL: Where?! PHOEBE: On the touchy. ROSS: And PHOEBE: No, I know! PHOEBE: I-I’m sorry, but the moment I touch him, I just wanna throw out my old oath and take a new, dirty one. MONICA: Well, next time your massaging him, you should try and distract yourself. JOEY: Yeah! Yeah! Yeah! Like-like when I’m doing something exciting and I don’t wanna get CHANDLER: Thank you, Joey. JOEY: No-no, thank you. </s>'\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> ROSS: Or! Or, we could go to the bank, close our accounts and cut them off at the source.</s>  CHANDLER: You’re a genius!  JOEY: Aww, man, now we won’t be bank buddies!  CHANDLER: Now, there’s two reasons.  PHOEBE: Hey.  ALL: Hey!  PHOEBE: Ohh, you guys, remember that cute client I told you about? I bit him.  RACHEL: Where?!  PHOEBE\n",
      "\n",
      "Token length stats: min=13, mean=212.1, max=416, n=1109\n",
      "================================================================================\n",
      "DEBUG 1 | dialog=0 | uttid=0 | label=surprise\n",
      "RAW strict (repr so you see </s>):\n",
      "\"<s> </s> MARK: Why do all you’re coffee mugs have numbers on the bottom? </s>  RACHEL: Oh. That’s so Monica can keep track. That way if one on them is missing, she can be like, ‘Where’s number 27?!’ RACHEL: Y'know what? </s>\"\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s></s> MARK: Why do all you’re coffee mugs have numbers on the bottom?</s>  RACHEL: Oh. That’s so Monica can keep track. That way if one on them is missing, she can be like, ‘Where’s number 27?!’  RACHEL: Y'know what?</s>\n",
      "================================================================================\n",
      "DEBUG 2 | dialog=0 | uttid=1 | label=anger\n",
      "RAW strict (repr so you see </s>):\n",
      "\"<s> MARK: Why do all you’re coffee mugs have numbers on the bottom?  </s> RACHEL: Oh. That’s so Monica can keep track. That way if one on them is missing, she can be like, ‘Where’s number 27?!’ </s>  RACHEL: Y'know what? </s>\"\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> MARK: Why do all you’re coffee mugs have numbers on the bottom? </s> RACHEL: Oh. That’s so Monica can keep track. That way if one on them is missing, she can be like, ‘Where’s number 27?!’</s>  RACHEL: Y'know what?</s>\n",
      "================================================================================\n",
      "DEBUG 3 | dialog=0 | uttid=2 | label=neutral\n",
      "RAW strict (repr so you see </s>):\n",
      "\"<s> MARK: Why do all you’re coffee mugs have numbers on the bottom? RACHEL: Oh. That’s so Monica can keep track. That way if one on them is missing, she can be like, ‘Where’s number 27?!’  </s> RACHEL: Y'know what? </s> </s>\"\n",
      "\n",
      "DECODED (first 120 tokens):\n",
      "<s> MARK: Why do all you’re coffee mugs have numbers on the bottom?  RACHEL: Oh. That’s so Monica can keep track. That way if one on them is missing, she can be like, ‘Where’s number 27?!’ </s> RACHEL: Y'know what?</s></s>\n",
      "\n",
      "Token length stats: min=10, mean=216.7, max=511, n=2610\n",
      "\n",
      "==================== SEED 42 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-2727024850.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8743' max='8743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8743/8743 07:32, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.530900</td>\n",
       "      <td>1.558906</td>\n",
       "      <td>0.423805</td>\n",
       "      <td>0.252297</td>\n",
       "      <td>0.085045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.134700</td>\n",
       "      <td>1.180762</td>\n",
       "      <td>0.611362</td>\n",
       "      <td>0.573903</td>\n",
       "      <td>0.374167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.016000</td>\n",
       "      <td>1.129711</td>\n",
       "      <td>0.626691</td>\n",
       "      <td>0.589365</td>\n",
       "      <td>0.397288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.888200</td>\n",
       "      <td>1.148630</td>\n",
       "      <td>0.627592</td>\n",
       "      <td>0.601054</td>\n",
       "      <td>0.427182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.784300</td>\n",
       "      <td>1.191525</td>\n",
       "      <td>0.628494</td>\n",
       "      <td>0.607594</td>\n",
       "      <td>0.461296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.758000</td>\n",
       "      <td>1.157616</td>\n",
       "      <td>0.637511</td>\n",
       "      <td>0.615610</td>\n",
       "      <td>0.459843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.699700</td>\n",
       "      <td>1.213728</td>\n",
       "      <td>0.630298</td>\n",
       "      <td>0.610259</td>\n",
       "      <td>0.464973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed42/epoch_01\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed42/epoch_02\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed42/epoch_03\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed42/epoch_04\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed42/epoch_05\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed42/epoch_06\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed42/epoch_07\n",
      "Best checkpoint (trainer): roberta_meld_final_seed42/checkpoint-7494\n",
      "✅ Saved BEST folder to: roberta_meld_final_seed42_BEST\n",
      "✅ Epoch checkpoints saved in: /content/epoch_checkpoints_seed42\n",
      "epoch_01\n",
      "epoch_02\n",
      "epoch_03\n",
      "epoch_04\n",
      "epoch_05\n",
      "epoch_06\n",
      "epoch_07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/164 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: {'eval_loss': 1.1344406604766846, 'eval_acc': 0.650191570881226, 'eval_weighted_f1': 0.6369315875903244, 'eval_macro_f1': 0.4462754578316832, 'eval_runtime': 3.3865, 'eval_samples_per_second': 770.703, 'eval_steps_per_second': 48.427, 'epoch': 7.0}\n",
      "\n",
      "==================== SEED 43 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-2727024850.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8743' max='8743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8743/8743 07:34, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.491700</td>\n",
       "      <td>1.580039</td>\n",
       "      <td>0.421100</td>\n",
       "      <td>0.288358</td>\n",
       "      <td>0.116297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.121000</td>\n",
       "      <td>1.192025</td>\n",
       "      <td>0.602344</td>\n",
       "      <td>0.555015</td>\n",
       "      <td>0.362344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.012600</td>\n",
       "      <td>1.124837</td>\n",
       "      <td>0.631199</td>\n",
       "      <td>0.597008</td>\n",
       "      <td>0.402997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.932100</td>\n",
       "      <td>1.124644</td>\n",
       "      <td>0.632101</td>\n",
       "      <td>0.603581</td>\n",
       "      <td>0.413351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.842800</td>\n",
       "      <td>1.148727</td>\n",
       "      <td>0.635708</td>\n",
       "      <td>0.605402</td>\n",
       "      <td>0.443386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.778100</td>\n",
       "      <td>1.170817</td>\n",
       "      <td>0.640216</td>\n",
       "      <td>0.613942</td>\n",
       "      <td>0.464247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.685500</td>\n",
       "      <td>1.140224</td>\n",
       "      <td>0.650135</td>\n",
       "      <td>0.629942</td>\n",
       "      <td>0.487833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed43/epoch_01\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed43/epoch_02\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed43/epoch_03\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed43/epoch_04\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed43/epoch_05\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed43/epoch_06\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed43/epoch_07\n",
      "Best checkpoint (trainer): roberta_meld_final_seed43/checkpoint-8743\n",
      "✅ Saved BEST folder to: roberta_meld_final_seed43_BEST\n",
      "✅ Epoch checkpoints saved in: /content/epoch_checkpoints_seed43\n",
      "epoch_01\n",
      "epoch_02\n",
      "epoch_03\n",
      "epoch_04\n",
      "epoch_05\n",
      "epoch_06\n",
      "epoch_07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/164 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: {'eval_loss': 1.1489425897598267, 'eval_acc': 0.6524904214559387, 'eval_weighted_f1': 0.6410403495776756, 'eval_macro_f1': 0.4607877071500737, 'eval_runtime': 3.2984, 'eval_samples_per_second': 791.291, 'eval_steps_per_second': 49.721, 'epoch': 7.0}\n",
      "\n",
      "==================== SEED 44 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-2727024850.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8743' max='8743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8743/8743 07:38, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.456200</td>\n",
       "      <td>1.408934</td>\n",
       "      <td>0.510370</td>\n",
       "      <td>0.403659</td>\n",
       "      <td>0.206536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.093100</td>\n",
       "      <td>1.123991</td>\n",
       "      <td>0.637511</td>\n",
       "      <td>0.611225</td>\n",
       "      <td>0.416285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.956200</td>\n",
       "      <td>1.144925</td>\n",
       "      <td>0.619477</td>\n",
       "      <td>0.592064</td>\n",
       "      <td>0.393581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.853100</td>\n",
       "      <td>1.127971</td>\n",
       "      <td>0.634806</td>\n",
       "      <td>0.608026</td>\n",
       "      <td>0.425155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.775800</td>\n",
       "      <td>1.145210</td>\n",
       "      <td>0.639315</td>\n",
       "      <td>0.620216</td>\n",
       "      <td>0.469129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.684800</td>\n",
       "      <td>1.195663</td>\n",
       "      <td>0.631199</td>\n",
       "      <td>0.613186</td>\n",
       "      <td>0.465355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.634600</td>\n",
       "      <td>1.198571</td>\n",
       "      <td>0.637511</td>\n",
       "      <td>0.623483</td>\n",
       "      <td>0.485906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed44/epoch_01\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed44/epoch_02\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed44/epoch_03\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed44/epoch_04\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed44/epoch_05\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed44/epoch_06\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed44/epoch_07\n",
      "Best checkpoint (trainer): roberta_meld_final_seed44/checkpoint-8743\n",
      "✅ Saved BEST folder to: roberta_meld_final_seed44_BEST\n",
      "✅ Epoch checkpoints saved in: /content/epoch_checkpoints_seed44\n",
      "epoch_01\n",
      "epoch_02\n",
      "epoch_03\n",
      "epoch_04\n",
      "epoch_05\n",
      "epoch_06\n",
      "epoch_07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/164 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: {'eval_loss': 1.1867961883544922, 'eval_acc': 0.6532567049808429, 'eval_weighted_f1': 0.6459490997242914, 'eval_macro_f1': 0.4719797828680748, 'eval_runtime': 3.3111, 'eval_samples_per_second': 788.259, 'eval_steps_per_second': 49.53, 'epoch': 7.0}\n",
      "\n",
      "==================== SEED 45 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-2727024850.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8743' max='8743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8743/8743 07:30, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.474500</td>\n",
       "      <td>1.552359</td>\n",
       "      <td>0.441839</td>\n",
       "      <td>0.299886</td>\n",
       "      <td>0.130189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.075500</td>\n",
       "      <td>1.137187</td>\n",
       "      <td>0.624887</td>\n",
       "      <td>0.592779</td>\n",
       "      <td>0.391527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.964500</td>\n",
       "      <td>1.083005</td>\n",
       "      <td>0.640216</td>\n",
       "      <td>0.607662</td>\n",
       "      <td>0.409522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.871300</td>\n",
       "      <td>1.124163</td>\n",
       "      <td>0.641118</td>\n",
       "      <td>0.607491</td>\n",
       "      <td>0.428182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.780900</td>\n",
       "      <td>1.143821</td>\n",
       "      <td>0.642020</td>\n",
       "      <td>0.619297</td>\n",
       "      <td>0.469652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.707400</td>\n",
       "      <td>1.174290</td>\n",
       "      <td>0.642020</td>\n",
       "      <td>0.624946</td>\n",
       "      <td>0.482548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.641300</td>\n",
       "      <td>1.183119</td>\n",
       "      <td>0.639315</td>\n",
       "      <td>0.622962</td>\n",
       "      <td>0.480685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed45/epoch_01\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed45/epoch_02\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed45/epoch_03\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed45/epoch_04\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed45/epoch_05\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed45/epoch_06\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed45/epoch_07\n",
      "Best checkpoint (trainer): roberta_meld_final_seed45/checkpoint-7494\n",
      "✅ Saved BEST folder to: roberta_meld_final_seed45_BEST\n",
      "✅ Epoch checkpoints saved in: /content/epoch_checkpoints_seed45\n",
      "epoch_01\n",
      "epoch_02\n",
      "epoch_03\n",
      "epoch_04\n",
      "epoch_05\n",
      "epoch_06\n",
      "epoch_07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/164 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: {'eval_loss': 1.1661546230316162, 'eval_acc': 0.6429118773946361, 'eval_weighted_f1': 0.6343424462993786, 'eval_macro_f1': 0.44388329029297224, 'eval_runtime': 3.3677, 'eval_samples_per_second': 775.006, 'eval_steps_per_second': 48.698, 'epoch': 7.0}\n",
      "\n",
      "==================== SEED 46 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-2727024850.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8336' max='8743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8336/8743 07:26 < 00:21, 18.65 it/s, Epoch 6.67/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.516600</td>\n",
       "      <td>1.584179</td>\n",
       "      <td>0.427412</td>\n",
       "      <td>0.262209</td>\n",
       "      <td>0.092835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.142200</td>\n",
       "      <td>1.139344</td>\n",
       "      <td>0.623986</td>\n",
       "      <td>0.589345</td>\n",
       "      <td>0.394680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.013700</td>\n",
       "      <td>1.118995</td>\n",
       "      <td>0.636610</td>\n",
       "      <td>0.603078</td>\n",
       "      <td>0.406094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.880100</td>\n",
       "      <td>1.141139</td>\n",
       "      <td>0.642020</td>\n",
       "      <td>0.609267</td>\n",
       "      <td>0.443433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.809700</td>\n",
       "      <td>1.095982</td>\n",
       "      <td>0.648332</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.481581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.772900</td>\n",
       "      <td>1.124524</td>\n",
       "      <td>0.653742</td>\n",
       "      <td>0.635893</td>\n",
       "      <td>0.504608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed46/epoch_01\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed46/epoch_02\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed46/epoch_03\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed46/epoch_04\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed46/epoch_05\n",
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed46/epoch_06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8743' max='8743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8743/8743 07:51, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Weighted F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.516600</td>\n",
       "      <td>1.584179</td>\n",
       "      <td>0.427412</td>\n",
       "      <td>0.262209</td>\n",
       "      <td>0.092835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.142200</td>\n",
       "      <td>1.139344</td>\n",
       "      <td>0.623986</td>\n",
       "      <td>0.589345</td>\n",
       "      <td>0.394680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.013700</td>\n",
       "      <td>1.118995</td>\n",
       "      <td>0.636610</td>\n",
       "      <td>0.603078</td>\n",
       "      <td>0.406094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.880100</td>\n",
       "      <td>1.141139</td>\n",
       "      <td>0.642020</td>\n",
       "      <td>0.609267</td>\n",
       "      <td>0.443433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.809700</td>\n",
       "      <td>1.095982</td>\n",
       "      <td>0.648332</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.481581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.772900</td>\n",
       "      <td>1.124524</td>\n",
       "      <td>0.653742</td>\n",
       "      <td>0.635893</td>\n",
       "      <td>0.504608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.683100</td>\n",
       "      <td>1.141993</td>\n",
       "      <td>0.651037</td>\n",
       "      <td>0.633200</td>\n",
       "      <td>0.502614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved epoch checkpoint to: /content/epoch_checkpoints_seed46/epoch_07\n",
      "Best checkpoint (trainer): roberta_meld_final_seed46/checkpoint-7494\n",
      "✅ Saved BEST folder to: roberta_meld_final_seed46_BEST\n",
      "✅ Epoch checkpoints saved in: /content/epoch_checkpoints_seed46\n",
      "epoch_01\n",
      "epoch_02\n",
      "epoch_03\n",
      "epoch_04\n",
      "epoch_05\n",
      "epoch_06\n",
      "epoch_07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/164 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: {'eval_loss': 1.1374412775039673, 'eval_acc': 0.6467432950191571, 'eval_weighted_f1': 0.6369860282134358, 'eval_macro_f1': 0.458966379841883, 'eval_runtime': 3.2727, 'eval_samples_per_second': 797.504, 'eval_steps_per_second': 50.111, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>best_ckpt</th>\n",
       "      <th>best_dir</th>\n",
       "      <th>epoch_root</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_weighted_f1</th>\n",
       "      <th>test_macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>roberta_meld_final_seed42/checkpoint-7494</td>\n",
       "      <td>roberta_meld_final_seed42_BEST</td>\n",
       "      <td>/content/epoch_checkpoints_seed42</td>\n",
       "      <td>0.650192</td>\n",
       "      <td>0.636932</td>\n",
       "      <td>0.446275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>roberta_meld_final_seed43/checkpoint-8743</td>\n",
       "      <td>roberta_meld_final_seed43_BEST</td>\n",
       "      <td>/content/epoch_checkpoints_seed43</td>\n",
       "      <td>0.652490</td>\n",
       "      <td>0.641040</td>\n",
       "      <td>0.460788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>roberta_meld_final_seed44/checkpoint-8743</td>\n",
       "      <td>roberta_meld_final_seed44_BEST</td>\n",
       "      <td>/content/epoch_checkpoints_seed44</td>\n",
       "      <td>0.653257</td>\n",
       "      <td>0.645949</td>\n",
       "      <td>0.471980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>roberta_meld_final_seed45/checkpoint-7494</td>\n",
       "      <td>roberta_meld_final_seed45_BEST</td>\n",
       "      <td>/content/epoch_checkpoints_seed45</td>\n",
       "      <td>0.642912</td>\n",
       "      <td>0.634342</td>\n",
       "      <td>0.443883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>roberta_meld_final_seed46/checkpoint-7494</td>\n",
       "      <td>roberta_meld_final_seed46_BEST</td>\n",
       "      <td>/content/epoch_checkpoints_seed46</td>\n",
       "      <td>0.646743</td>\n",
       "      <td>0.636986</td>\n",
       "      <td>0.458966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed                                  best_ckpt  \\\n",
       "0    42  roberta_meld_final_seed42/checkpoint-7494   \n",
       "1    43  roberta_meld_final_seed43/checkpoint-8743   \n",
       "2    44  roberta_meld_final_seed44/checkpoint-8743   \n",
       "3    45  roberta_meld_final_seed45/checkpoint-7494   \n",
       "4    46  roberta_meld_final_seed46/checkpoint-7494   \n",
       "\n",
       "                         best_dir                         epoch_root  \\\n",
       "0  roberta_meld_final_seed42_BEST  /content/epoch_checkpoints_seed42   \n",
       "1  roberta_meld_final_seed43_BEST  /content/epoch_checkpoints_seed43   \n",
       "2  roberta_meld_final_seed44_BEST  /content/epoch_checkpoints_seed44   \n",
       "3  roberta_meld_final_seed45_BEST  /content/epoch_checkpoints_seed45   \n",
       "4  roberta_meld_final_seed46_BEST  /content/epoch_checkpoints_seed46   \n",
       "\n",
       "   test_acc  test_weighted_f1  test_macro_f1  \n",
       "0  0.650192          0.636932       0.446275  \n",
       "1  0.652490          0.641040       0.460788  \n",
       "2  0.653257          0.645949       0.471980  \n",
       "3  0.642912          0.634342       0.443883  \n",
       "4  0.646743          0.636986       0.458966  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_acc</th>\n",
       "      <td>0.649119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_weighted_f1</th>\n",
       "      <td>0.639050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_macro_f1</th>\n",
       "      <td>0.456379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean\n",
       "test_acc          0.649119\n",
       "test_weighted_f1  0.639050\n",
       "test_macro_f1     0.456379"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_acc</th>\n",
       "      <td>0.004296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_weighted_f1</th>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_macro_f1</th>\n",
       "      <td>0.011486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       std\n",
       "test_acc          0.004296\n",
       "test_weighted_f1  0.004541\n",
       "test_macro_f1     0.011486"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ==========================\n",
    "#   Save model+tokenizer per EPOCH and per SEED\n",
    "# - Saves: /content/epoch_checkpoints_seed{seed}/epoch_01, epoch_02, ...\n",
    "# - Also keeps the Trainer's \"best checkpoint\" and copies it to *_BEST\n",
    "# ==========================\n",
    "\n",
    "import os, shutil\n",
    "import pandas as pd\n",
    "from transformers import TrainerCallback, TrainingArguments, Trainer\n",
    "\n",
    "best_lr = study.best_params[\"lr\"]\n",
    "\n",
    "SEEDS = [42, 43, 44, 45, 46]\n",
    "MAX_LEN = 512\n",
    "\n",
    "# Build datasets ONCE (same for all seeds)\n",
    "train_ds = build_context_dataset_with_text_target_has_speaker(train_df, tok, max_length=MAX_LEN, speaker_caps=True)\n",
    "val_ds   = build_context_dataset_with_text_target_has_speaker(val_df,   tok, max_length=MAX_LEN, speaker_caps=True)\n",
    "test_ds  = build_context_dataset_with_text_target_has_speaker(test_df,  tok, max_length=MAX_LEN, speaker_caps=True)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# ---------- callback: save at end of each epoch ----------\n",
    "class SaveByEpochCallback(TrainerCallback):\n",
    "    def __init__(self, out_root, tokenizer):\n",
    "        self.out_root = out_root\n",
    "        self.tokenizer = tokenizer\n",
    "        os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        model = kwargs[\"model\"]\n",
    "        ep = state.epoch\n",
    "        ep_i = int(round(ep)) if ep is not None else 0\n",
    "\n",
    "        save_dir = os.path.join(self.out_root, f\"epoch_{ep_i:02d}\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        model.save_pretrained(save_dir)\n",
    "        self.tokenizer.save_pretrained(save_dir)\n",
    "        print(f\"✅ Saved epoch checkpoint to: {save_dir}\")\n",
    "        return control\n",
    "\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(\"\\n\" + \"=\"*20, \"SEED\", seed, \"=\"*20)\n",
    "    set_seed(seed)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_BASE,\n",
    "        num_labels=len(LABELS),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    out_dir = f\"roberta_meld_final_seed{seed}\"\n",
    "\n",
    "    #  where we save epoch checkpoints for this seed\n",
    "    epoch_root = f\"/content/epoch_checkpoints_seed{seed}\"\n",
    "    if os.path.exists(epoch_root):\n",
    "        shutil.rmtree(epoch_root)\n",
    "    os.makedirs(epoch_root, exist_ok=True)\n",
    "\n",
    "    epoch_saver = SaveByEpochCallback(epoch_root, tok)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=out_dir,\n",
    "\n",
    "        # use the official arg name (safer than eval_strategy)\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,  # keeps only 2 trainer checkpoints (we keep all epochs separately)\n",
    "\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"weighted_f1\",\n",
    "        greater_is_better=True,\n",
    "\n",
    "        learning_rate=best_lr,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=16,\n",
    "\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.20,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=\"none\",\n",
    "        seed=seed,\n",
    "        logging_steps=200,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        data_collator=collator,\n",
    "        tokenizer=tok,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[epoch_saver],   #  save model+tokenizer per epoch\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    best_ckpt = trainer.state.best_model_checkpoint\n",
    "    print(\"Best checkpoint (trainer):\", best_ckpt)\n",
    "\n",
    "    # ===== Save BEST model folder  =====\n",
    "    best_dir = f\"{out_dir}_BEST\"\n",
    "    if os.path.exists(best_dir):\n",
    "        shutil.rmtree(best_dir)\n",
    "    shutil.copytree(best_ckpt, best_dir)\n",
    "    tok.save_pretrained(best_dir)\n",
    "    print(\"✅ Saved BEST folder to:\", best_dir)\n",
    "\n",
    "    # Show epoch folders saved for this seed\n",
    "    print(\"✅ Epoch checkpoints saved in:\", epoch_root)\n",
    "    !ls -1 \"$epoch_root\" | head\n",
    "\n",
    "    # ===== Test (only after training) =====\n",
    "    test_metrics = trainer.evaluate(test_ds)\n",
    "    print(\"TEST:\", test_metrics)\n",
    "\n",
    "    rows.append({\n",
    "        \"seed\": seed,\n",
    "        \"best_ckpt\": best_ckpt,\n",
    "        \"best_dir\": best_dir,\n",
    "        \"epoch_root\": epoch_root,\n",
    "        \"test_acc\": float(test_metrics[\"eval_acc\"]),\n",
    "        \"test_weighted_f1\": float(test_metrics[\"eval_weighted_f1\"]),\n",
    "        \"test_macro_f1\": float(test_metrics[\"eval_macro_f1\"]),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "display(df)\n",
    "\n",
    "print(\"\\nMEAN:\")\n",
    "display(df[[\"test_acc\",\"test_weighted_f1\",\"test_macro_f1\"]].mean().to_frame(\"mean\"))\n",
    "\n",
    "print(\"\\nSTD:\")\n",
    "display(df[[\"test_acc\",\"test_weighted_f1\",\"test_macro_f1\"]].std().to_frame(\"std\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "024c7c55d1b14ac18db46dadb9c7c3a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_756c3f1ebe07466f96a40c02283ce3ed",
      "placeholder": "​",
      "style": "IPY_MODEL_570a8a1de7b1475489b0d157d3b3f2fc",
      "value": "merges.txt: 100%"
     }
    },
    "091390d1fc724f229f73a54217ebfabe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12c45d70257f4647a21fb1a51dc0a90a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fef464bdfd9f4ad68d97dd714f82c328",
       "IPY_MODEL_c23891fcb08f433f8acafaaee957efb0",
       "IPY_MODEL_14d6a26a70e04608a2685c317accc608"
      ],
      "layout": "IPY_MODEL_1f33c90480484145a80dc1caa885022c"
     }
    },
    "14d6a26a70e04608a2685c317accc608": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b02213cce5654490b50d3c3c19c6dbd1",
      "placeholder": "​",
      "style": "IPY_MODEL_be5d681511aa404ba87cfa1348b40745",
      "value": " 499M/499M [00:01&lt;00:00, 408MB/s]"
     }
    },
    "18475146fcba40e2920b5a0b569e761d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bb2e62bc2e445488eab1ee055a65ad4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dccc369a736b45ea8e18c6284836350c",
       "IPY_MODEL_ea413c16a7c74d6aae871072e2cab1f2",
       "IPY_MODEL_39bae3abf66b456e8fb20af7154b999c"
      ],
      "layout": "IPY_MODEL_2caba47770bf4be2be4837c02ad9c9f9"
     }
    },
    "1f33c90480484145a80dc1caa885022c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2000e92c5ace40a58e8193764c5c0b30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c261301f9043af8899501fbeea972f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2caba47770bf4be2be4837c02ad9c9f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31aa62dc16554ab0989d1e4809c7d9eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_32f82514615546a49bb0aef7f33180d3",
       "IPY_MODEL_8108b8328b084ab18d865073d22cb9de",
       "IPY_MODEL_9e84b975814f4468af7b08d8c4a2c943"
      ],
      "layout": "IPY_MODEL_bab11628d3ba41ad88d5ed37b24a9d26"
     }
    },
    "32f82514615546a49bb0aef7f33180d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edeef8c9a8c540898fd67b87d3f6c382",
      "placeholder": "​",
      "style": "IPY_MODEL_533239ef45d5439c9b4ea51153ef55d8",
      "value": "vocab.json: 100%"
     }
    },
    "39bae3abf66b456e8fb20af7154b999c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2000e92c5ace40a58e8193764c5c0b30",
      "placeholder": "​",
      "style": "IPY_MODEL_aad3d3f3afae4bb886f6e0a70b5f055e",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 3.71MB/s]"
     }
    },
    "39c9e93fbca146df9989b2cbf4e3e0e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41961ab8885b498094ce35e54453c729": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45b146146f304230b88f1dbdc5ae9461": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b283fc597ab4a348ca21e2d813d4c52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b80b0c4e3c049d8b014417fd6a4067d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4bf1de8851ea4526a0eace2de7cb1a22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cdb3f04b0a34eeb93857cadf89f7874": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f719933644d41009facb04d1f38daf8",
       "IPY_MODEL_f56d893685f84473845dfc9c4db5b1c8",
       "IPY_MODEL_6a45997ddcb84cba80cc453d342f6ae2"
      ],
      "layout": "IPY_MODEL_81f125d7e3d24e7eb3a04420eefb78b8"
     }
    },
    "4f719933644d41009facb04d1f38daf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1bb0ba913e64532add1c55bea362205",
      "placeholder": "​",
      "style": "IPY_MODEL_61679ec04f0d486687389d0324e24b3f",
      "value": "config.json: 100%"
     }
    },
    "533239ef45d5439c9b4ea51153ef55d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "570a8a1de7b1475489b0d157d3b3f2fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57892cbdf49845afb3e4c9af1791ff37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cf65df0dfd1469f82a45fc6c4569ce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_091390d1fc724f229f73a54217ebfabe",
      "placeholder": "​",
      "style": "IPY_MODEL_18475146fcba40e2920b5a0b569e761d",
      "value": " 25.0/25.0 [00:00&lt;00:00, 3.23kB/s]"
     }
    },
    "5ff38f1111e64611b074bb7b9ecdfe16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e22b5ba9843b4e059296ae8584023a57",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8265aaadffdf4d57a8acb38097bd9158",
      "value": 25
     }
    },
    "612c8b14a3eb42019139000e54632b0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94101cb911964424987369056f253a6a",
      "placeholder": "​",
      "style": "IPY_MODEL_39c9e93fbca146df9989b2cbf4e3e0e2",
      "value": " 456k/456k [00:00&lt;00:00, 1.14MB/s]"
     }
    },
    "61679ec04f0d486687389d0324e24b3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61eec4164ab142b99409fad380eb824f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a45997ddcb84cba80cc453d342f6ae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_757fa4aaa1684ae5940f434f05819ca1",
      "placeholder": "​",
      "style": "IPY_MODEL_8f69cba65034425aa7d94f659f7707ea",
      "value": " 481/481 [00:00&lt;00:00, 66.1kB/s]"
     }
    },
    "6c6fed7960104954a106c7ec3fa58165": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "756c3f1ebe07466f96a40c02283ce3ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "757fa4aaa1684ae5940f434f05819ca1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8108b8328b084ab18d865073d22cb9de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b283fc597ab4a348ca21e2d813d4c52",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9071509d3b21462d9aad45a4b229bd6f",
      "value": 898823
     }
    },
    "8150941fea4b4a08a7fa339164b79b93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "81f125d7e3d24e7eb3a04420eefb78b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8265aaadffdf4d57a8acb38097bd9158": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ecbe5d79181457089ee06b05b6c05bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f69cba65034425aa7d94f659f7707ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9071509d3b21462d9aad45a4b229bd6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "937605bb287b429c971aef2ca24e57cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "94101cb911964424987369056f253a6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b7d3f0261ba45b4bfae68b48c6ec89b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e84b975814f4468af7b08d8c4a2c943": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7d8e0954664464a9c5a0fa0ba8fa389",
      "placeholder": "​",
      "style": "IPY_MODEL_a5ec8504c44b4fe0a2a63115710b8056",
      "value": " 899k/899k [00:00&lt;00:00, 1.12MB/s]"
     }
    },
    "a5ec8504c44b4fe0a2a63115710b8056": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7d8e0954664464a9c5a0fa0ba8fa389": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aad3d3f3afae4bb886f6e0a70b5f055e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acf8464c1723416ea7ab4e7a1526e643": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af0c7b59ac69480491607310b6e36aa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c261301f9043af8899501fbeea972f",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8150941fea4b4a08a7fa339164b79b93",
      "value": 456318
     }
    },
    "af59c0a38cec4b30af1868bcb454578e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_024c7c55d1b14ac18db46dadb9c7c3a6",
       "IPY_MODEL_af0c7b59ac69480491607310b6e36aa1",
       "IPY_MODEL_612c8b14a3eb42019139000e54632b0a"
      ],
      "layout": "IPY_MODEL_6c6fed7960104954a106c7ec3fa58165"
     }
    },
    "b02213cce5654490b50d3c3c19c6dbd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b28a71feaf644e088d4808e383c69a3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bab11628d3ba41ad88d5ed37b24a9d26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be5d681511aa404ba87cfa1348b40745": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c23891fcb08f433f8acafaaee957efb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f91c79f430a74d2c894d902bbedc1a5f",
      "max": 498818054,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ecbe5d79181457089ee06b05b6c05bc",
      "value": 498818054
     }
    },
    "dad63804654c434fbea3a6673d574fc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57892cbdf49845afb3e4c9af1791ff37",
      "placeholder": "​",
      "style": "IPY_MODEL_9b7d3f0261ba45b4bfae68b48c6ec89b",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "dccc369a736b45ea8e18c6284836350c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41961ab8885b498094ce35e54453c729",
      "placeholder": "​",
      "style": "IPY_MODEL_4b80b0c4e3c049d8b014417fd6a4067d",
      "value": "tokenizer.json: 100%"
     }
    },
    "e22b5ba9843b4e059296ae8584023a57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea413c16a7c74d6aae871072e2cab1f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b28a71feaf644e088d4808e383c69a3c",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_937605bb287b429c971aef2ca24e57cd",
      "value": 1355863
     }
    },
    "edeef8c9a8c540898fd67b87d3f6c382": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1bb0ba913e64532add1c55bea362205": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f56d893685f84473845dfc9c4db5b1c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61eec4164ab142b99409fad380eb824f",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45b146146f304230b88f1dbdc5ae9461",
      "value": 481
     }
    },
    "f749a57a41f34a529b77682f177a57fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f91c79f430a74d2c894d902bbedc1a5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faf1e39242704fc3a43ca749a7b8b375": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dad63804654c434fbea3a6673d574fc2",
       "IPY_MODEL_5ff38f1111e64611b074bb7b9ecdfe16",
       "IPY_MODEL_5cf65df0dfd1469f82a45fc6c4569ce2"
      ],
      "layout": "IPY_MODEL_4bf1de8851ea4526a0eace2de7cb1a22"
     }
    },
    "fef464bdfd9f4ad68d97dd714f82c328": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f749a57a41f34a529b77682f177a57fe",
      "placeholder": "​",
      "style": "IPY_MODEL_acf8464c1723416ea7ab4e7a1526e643",
      "value": "model.safetensors: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

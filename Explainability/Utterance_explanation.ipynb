{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 1) Mount Google Drive (optional)\n",
    "# =======================\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 2) Install dependencies\n",
    "# =======================\n",
    "\n",
    "!pip install optimus\n",
    "\n",
    "!pip install lime\n",
    "\n",
    "!pip install  captum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 3) Imports and run configuration\n",
    "# =======================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "OUT_DIR = \"/content/plot_1_7\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_ID = \"/content/drive/MyDrive/epoch_checkpoints_seed45_finetuned_roberta/epoch_04\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Text to explain\n",
    "TEXT = \"Push!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 4) Load model and tokenizer\n",
    "# =======================\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    output_attentions=True\n",
    ").to(DEVICE).eval()\n",
    "\n",
    "id2label = model.config.id2label\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "class_names = [id2label[i] for i in range(len(id2label))]\n",
    "\n",
    "print(f\"[Utterance]\\n{TEXT}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 5) Token post-processing helpers\n",
    "# =======================\n",
    "\n",
    "def predict_logits(texts):\n",
    "    enc = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=256).to(DEVICE)\n",
    "    with torch.inference_mode():\n",
    "        out = model(**enc)\n",
    "    return out.logits\n",
    "\n",
    "def predict_proba(texts):\n",
    "    logits = predict_logits(texts)\n",
    "    probs  = F.softmax(logits, dim=-1)\n",
    "    return probs.detach().cpu().numpy()\n",
    "\n",
    "def roberta_merge(tokens, scores=None, skip_special=True):\n",
    "    \"\"\"Merge RoBERTa byte-BPE pieces (Ġ) into words; mean-aggregate scores per word.\"\"\"\n",
    "    specials = set(tokenizer.all_special_tokens)\n",
    "    words, vals = [], []\n",
    "    cur, bag = \"\", []\n",
    "    it = zip(tokens, scores) if scores is not None else zip(tokens, [None]*len(tokens))\n",
    "    for t, s in it:\n",
    "        if skip_special and t in specials:\n",
    "            continue\n",
    "        t2 = t.replace(\"Ġ\", \" \")\n",
    "        if t2.startswith(\" \"):  # new word\n",
    "            if cur:\n",
    "                words.append(cur.strip()); vals.append(np.mean(bag) if bag else 0.0)\n",
    "            cur, bag = t2, [] if s is None else [s]\n",
    "        else:\n",
    "            cur += t2\n",
    "            if s is not None: bag.append(s)\n",
    "    if cur:\n",
    "        words.append(cur.strip()); vals.append(np.mean(bag) if bag else 0.0)\n",
    "    return (words, np.array(vals, float)) if scores is not None else (words, None)\n",
    "\n",
    "def drop_specials(tokens, scores=None):\n",
    "    specials = set(tokenizer.all_special_tokens)\n",
    "    keep_idx = [i for i,t in enumerate(tokens) if t not in specials]\n",
    "    toks = [tokens[i] for i in keep_idx]\n",
    "    if scores is None: return toks, None, keep_idx\n",
    "    return toks, np.asarray(scores)[keep_idx], keep_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 6) Select utterance and run forward pass\n",
    "# =======================\n",
    "\n",
    "enc = tokenizer(TEXT, return_tensors=\"pt\", truncation=True, padding=True, max_length=256).to(DEVICE)\n",
    "with torch.inference_mode():\n",
    "    out = model(**enc)\n",
    "logits = out.logits[0]\n",
    "probs  = F.softmax(logits, -1).cpu().numpy()\n",
    "pred_id = int(np.argmax(probs))\n",
    "pred_label = id2label[pred_id]\n",
    "print(f\"[Predicted] {pred_label}  |  probs: \" + \", \".join(f\"{id2label[i]}={probs[i]:.3f}\" for i in range(len(probs))))\n",
    "\n",
    "tokens_bpe = tokenizer.convert_ids_to_tokens(enc[\"input_ids\"][0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 7) GradientSHAP — token-level importance\n",
    "# =======================\n",
    "\n",
    "from captum.attr import GradientShap\n",
    "\n",
    "emb_layer = model.get_input_embeddings()\n",
    "\n",
    "def fwd_logits_from_emb(inputs_embeds, attention_mask, target_idx):\n",
    "    out = model(inputs_embeds=inputs_embeds, attention_mask=attention_mask, return_dict=True)\n",
    "    return out.logits[:, target_idx]\n",
    "\n",
    "inp_emb = emb_layer(enc[\"input_ids\"]).detach().requires_grad_(True)\n",
    "pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "pad_vec = emb_layer(torch.tensor([[pad_id]], device=DEVICE))\n",
    "\n",
    "# baselines = torch.stack([torch.zeros_like(inp_emb), pad_vec], dim=1)   # (1,2,T,D)\n",
    "baselines = torch.stack([torch.zeros_like(inp_emb), pad_vec.repeat(1, inp_emb.shape[1], 1)], dim=1).squeeze(0) # (2,T,D)\n",
    "\n",
    "gs = GradientShap(lambda embs, am: fwd_logits_from_emb(embs, am, pred_id))\n",
    "attr = gs.attribute(inp_emb, baselines=baselines, additional_forward_args=(enc[\"attention_mask\"],), n_samples=30, stdevs=0.0)\n",
    "tok_scores_gs = attr.sum(-1)[0].detach().cpu().numpy()\n",
    "# normalize for display\n",
    "tok_scores_gs = tok_scores_gs / (np.max(np.abs(tok_scores_gs)) + 1e-12)\n",
    "toks_nospec, scores_nospec, keep_idx = drop_specials(tokens_bpe, tok_scores_gs)\n",
    "words_gs, word_scores_gs = roberta_merge(toks_nospec, scores_nospec)\n",
    "\n",
    "plt.figure(figsize=(max(6, 0.45*len(words_gs)), 3))\n",
    "plt.bar(range(len(words_gs)), word_scores_gs)\n",
    "plt.xticks(range(len(words_gs)), words_gs, rotation=45, ha=\"right\")\n",
    "plt.title(f\"GradientSHAP tokens — {pred_label}\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR, \"01_gradshap_tokens.png\"), dpi=150); plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 8) SHAP waterfall plot (token contributions)\n",
    "# =======================\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# base value: class logit from pred_id baseline\n",
    "with torch.no_grad():\n",
    "    base_logit = fwd_logits_from_emb(baselines.mean(0, keepdim=True), enc[\"attention_mask\"], pred_id)\n",
    "    base_val = float(base_logit.item())\n",
    "\n",
    "# shap.Explanation , Captum scores\n",
    "subexp = shap.Explanation(\n",
    "    values=np.array(word_scores_gs, dtype=float),\n",
    "    base_values=base_val,\n",
    "    feature_names=words_gs\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "shap.plots.waterfall(subexp, max_display=len(words_gs), show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"gradshap_captum_waterfall.png\"), dpi=150)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 9) Layer Integrated Gradients (LIG)\n",
    "# =======================\n",
    "\n",
    "# Computes token attributions for the predicted class at:\n",
    "#   - the embedding module (\"Emb\")\n",
    "#   - each transformer block output (\"L0\" ... \"L{N-1}\")\n",
    "\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "SAVE_RAW = True  # Save TxL matrix + token/layer names to disk for reproducibility\n",
    "\n",
    "#  Prepare input embeddings and a simple baseline (zeros)\n",
    "inp_emb = emb_layer(enc[\"input_ids\"]).detach().requires_grad_(True)  # (1, T, D)\n",
    "am = enc[\"attention_mask\"]                                           # (1, T)\n",
    "baseline = torch.zeros_like(inp_emb)                                 # (1, T, D)\n",
    "\n",
    "#  Remove special tokens for visualization and for slicing attributions\n",
    "toks_nospec, _, keep_idx = drop_specials(tokens_bpe)\n",
    "toks_nospec = [t.replace(\"Ġ\", \" \") for t in toks_nospec]  # nicer display for RoBERTa BPE\n",
    "\n",
    "#  Choose target layers: embeddings + each encoder block output\n",
    "num_layers = model.config.num_hidden_layers\n",
    "layers = [(\"Emb\", model.roberta.embeddings)] + [\n",
    "    (f\"L{i}\", model.roberta.encoder.layer[i].output) for i in range(num_layers)\n",
    "]\n",
    "layer_names = [name for name, _ in layers]\n",
    "\n",
    "#  Compute a Tokens×Layers attribution matrix (TxL)\n",
    "TxL = []\n",
    "for _, target_layer in layers:\n",
    "    lig = LayerIntegratedGradients(\n",
    "        lambda embs, msk: fwd_logits_from_emb(embs, msk, pred_id),\n",
    "        target_layer\n",
    "    )\n",
    "    at = lig.attribute(\n",
    "        inputs=inp_emb,                        # (1, T, D)\n",
    "        baselines=baseline,                    # (1, T, D)\n",
    "        additional_forward_args=(am,),         # attention mask\n",
    "        n_steps=32,                            # 32–64 is a reasonable tradeoff\n",
    "        internal_batch_size=8\n",
    "    )  # -> (1, T, D)\n",
    "\n",
    "    tok_attr = at.sum(-1)[0].detach().cpu().numpy()  # (T,)\n",
    "    tok_attr = tok_attr[keep_idx]                    # drop special-token positions\n",
    "    TxL.append(tok_attr)\n",
    "\n",
    "TxL = np.stack(TxL, axis=1)  # (T_no_special, L+1)\n",
    "\n",
    "#  Optionally save raw artifacts\n",
    "if SAVE_RAW:\n",
    "    np.save(os.path.join(OUT_DIR, \"LIG_tokens_layers.npy\"), TxL)\n",
    "    with open(os.path.join(OUT_DIR, \"LIG_tokens_nospecial.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(toks_nospec))\n",
    "    with open(os.path.join(OUT_DIR, \"LIG_layer_names.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\",\".join(layer_names))\n",
    "\n",
    "#  Heatmap: Tokens × Layers (normalized to [-1, 1] for display)\n",
    "V = TxL / (np.max(np.abs(TxL)) + 1e-12)\n",
    "plt.figure(figsize=(max(6, 0.35 * TxL.shape[0]), 0.42 * TxL.shape[1] + 2))\n",
    "plt.imshow(V.T, aspect=\"auto\", cmap=\"bwr\", vmin=-1, vmax=1)\n",
    "plt.yticks(range(len(layer_names)), layer_names)\n",
    "plt.xticks(range(len(toks_nospec)), toks_nospec, rotation=90)\n",
    "plt.colorbar(label=\"LIG (normalized)\")\n",
    "plt.title(f\"LIG Tokens×Layers — {id2label[pred_id]}\")\n",
    "plt.tight_layout()\n",
    "fp_hm = os.path.join(OUT_DIR, \"LIG_tokens_layers_heatmap.png\")\n",
    "plt.savefig(fp_hm, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"[saved]\", fp_hm)\n",
    "\n",
    "#  Per-layer curve: total attribution strength per layer (sum over tokens)\n",
    "layer_curve_abs = np.sum(np.abs(TxL), axis=0)\n",
    "layer_curve_abs = layer_curve_abs / (layer_curve_abs.max() + 1e-12)\n",
    "\n",
    "plt.figure(figsize=(7.5, 3.2))\n",
    "plt.plot(range(len(layer_names)), layer_curve_abs, marker=\"o\")\n",
    "plt.xticks(range(len(layer_names)), layer_names)\n",
    "plt.ylabel(\"Relative |LIG| intensity\")\n",
    "plt.xlabel(\"Layer (Emb + L0..)\")\n",
    "plt.title(f\"LIG per-layer (sum |attr|) — {id2label[pred_id]}\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.tight_layout()\n",
    "fp_pl = os.path.join(OUT_DIR, \"LIG_per_layer_curve.png\")\n",
    "plt.savefig(fp_pl, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"[saved]\", fp_pl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "#  Layer Gradient×Activation (LGXA) + plot\n",
    "# =======================\n",
    "\n",
    "# Computes token attributions for the predicted class at:\n",
    "#   - the embedding module (\"Emb\")\n",
    "#   - each transformer block output (\"L0\" ... \"L{N-1}\")\n",
    "#\n",
    "# Notes:\n",
    "# - LGXA does not require a baseline (unlike Integrated Gradients).\n",
    "# - This mirrors the LIG \"Tokens×Layers\" setup so the heatmaps are comparable.\n",
    "\n",
    "from captum.attr import LayerGradientXActivation\n",
    "\n",
    "SAVE_RAW = True  # Save TxL matrix + token/layer names for reproducibility\n",
    "\n",
    "pred_label = id2label[pred_id]\n",
    "\n",
    "# 1) Prepare input embeddings and attention mask\n",
    "inp_emb = emb_layer(enc[\"input_ids\"]).detach().requires_grad_(True)  # (1, T, D)\n",
    "am = enc[\"attention_mask\"]                                           # (1, T)\n",
    "\n",
    "# 2) Remove special tokens for visualization and slicing\n",
    "toks_nospec, _, keep_idx = drop_specials(tokens_bpe)\n",
    "toks_nospec = [t.replace(\"Ġ\", \" \") for t in toks_nospec]  # nicer display for RoBERTa BPE\n",
    "\n",
    "# 3) Choose target layers: embeddings + each encoder block output\n",
    "num_layers = model.config.num_hidden_layers\n",
    "layers = [(\"Emb\", model.roberta.embeddings)] + [\n",
    "    (f\"L{i}\", model.roberta.encoder.layer[i].output) for i in range(num_layers)\n",
    "]\n",
    "layer_names = [name for name, _ in layers]\n",
    "\n",
    "#  Compute a Tokens×Layers attribution matrix (TxL)\n",
    "TxL = []\n",
    "for _, target_layer in layers:\n",
    "    lgxa = LayerGradientXActivation(\n",
    "        lambda embs, msk: fwd_logits_from_emb(embs, msk, pred_id),\n",
    "        target_layer\n",
    "    )\n",
    "    at = lgxa.attribute(\n",
    "        inputs=inp_emb,                      # (1, T, D)\n",
    "        additional_forward_args=(am,)        # attention mask\n",
    "    )  # -> (1, T, D)\n",
    "\n",
    "    tok_attr = at.sum(-1)[0].detach().cpu().numpy()  # (T,)\n",
    "    tok_attr = tok_attr[keep_idx]                    # drop special-token positions\n",
    "    TxL.append(tok_attr)\n",
    "\n",
    "TxL = np.stack(TxL, axis=1)  # (T_no_special, L+1)\n",
    "\n",
    "#  Optionally save raw artifacts\n",
    "if SAVE_RAW:\n",
    "    np.save(os.path.join(OUT_DIR, \"LGXA_tokens_layers.npy\"), TxL)\n",
    "    with open(os.path.join(OUT_DIR, \"LGXA_tokens_nospecial.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(toks_nospec))\n",
    "    with open(os.path.join(OUT_DIR, \"LGXA_layer_names.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\",\".join(layer_names))\n",
    "\n",
    "#  Heatmap: Tokens × Layers (normalized to [-1, 1] for display)\n",
    "V = TxL / (np.max(np.abs(TxL)) + 1e-12)\n",
    "plt.figure(figsize=(max(6, 0.35 * TxL.shape[0]), 0.42 * TxL.shape[1] + 2))\n",
    "plt.imshow(V.T, aspect=\"auto\", cmap=\"bwr\", vmin=-1, vmax=1)\n",
    "plt.yticks(range(len(layer_names)), layer_names)\n",
    "plt.xticks(range(len(toks_nospec)), toks_nospec, rotation=90)\n",
    "plt.colorbar(label=\"LGXA (normalized)\")\n",
    "plt.title(f\"LGXA Tokens×Layers — {pred_label}\")\n",
    "plt.tight_layout()\n",
    "fp_hm = os.path.join(OUT_DIR, \"LGXA_tokens_layers_heatmap.png\")\n",
    "plt.savefig(fp_hm, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"[saved]\", fp_hm)\n",
    "\n",
    "#  Per-layer curve: total attribution strength per layer (sum over tokens)\n",
    "layer_curve_abs = np.sum(np.abs(TxL), axis=0)\n",
    "layer_curve_abs = layer_curve_abs / (layer_curve_abs.max() + 1e-12)\n",
    "\n",
    "plt.figure(figsize=(7.5, 3.2))\n",
    "plt.plot(range(len(layer_names)), layer_curve_abs, marker=\"o\")\n",
    "plt.xticks(range(len(layer_names)), layer_names)\n",
    "plt.ylabel(\"Relative |LGXA| intensity\")\n",
    "plt.xlabel(\"Layer (Emb + L0..)\")\n",
    "plt.title(f\"LGXA per-layer (sum |attr|) — {pred_label}\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.tight_layout()\n",
    "fp_pl = os.path.join(OUT_DIR, \"LGXA_per_layer_curve.png\")\n",
    "plt.savefig(fp_pl, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"[saved]\", fp_pl)\n",
    "\n",
    "# plot heatmap (tokens × layers)\n",
    "plt.figure(figsize=(max(6, 0.35*TxL.shape[0]), 0.4*TxL.shape[1] + 2))\n",
    "v = TxL / (np.max(np.abs(TxL)) + 1e-12)\n",
    "plt.imshow(v.T, aspect=\"auto\", cmap=\"bwr\", vmin=-1, vmax=1)\n",
    "plt.yticks(range(len(layer_names)), layer_names)\n",
    "plt.xticks(range(len(toks_nospec)), toks_nospec, rotation=90)\n",
    "plt.colorbar(label=\"LIG (norm)\")\n",
    "plt.title(f\"LIG Tokens×Layers — {pred_label}\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR, \"02_lig_tokens_layers.png\"), dpi=150); plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 11) KernelSHAP — token-level explanation\n",
    "# =======================\n",
    "\n",
    "# Produces:\n",
    "#   - sanity check: base + sum(phi) ~ logit(target_class)\n",
    "#   - bar plot of top-|phi| tokens\n",
    "#   - waterfall plot\n",
    "#   - decision plot\n",
    "\n",
    "\n",
    "import shap\n",
    "\n",
    "MAX_EVALS = 3000   # increase for more stable estimates, but slower\n",
    "TOP_K     = 20     # how many tokens to show in the bar plot\n",
    "SAVE_RAW  = False  # set True if you want to save sv object later\n",
    "\n",
    "#  Text masker (HuggingFace tokenizer)\n",
    "masker = shap.maskers.Text(\n",
    "    tokenizer=tokenizer,\n",
    "    mask_token=(tokenizer.mask_token or \"<mask>\")\n",
    ")\n",
    "\n",
    "#  Explainer: return logits (not softmax) so that base + sum(phi) ≈ logit\n",
    "explainer = shap.Explainer(\n",
    "    lambda xs: predict_logits(list(xs)).detach().cpu().numpy(),\n",
    "    masker=masker,\n",
    "    output_names=class_names\n",
    ")\n",
    "\n",
    "#  Explain the current utterance\n",
    "sv = explainer([TEXT], max_evals=MAX_EVALS)\n",
    "\n",
    "# --- Extract tokens and SHAP values for the predicted class robustly ---\n",
    "tokens = list(np.array(sv.data[0]).reshape(-1))\n",
    "values = np.array(sv.values[0])\n",
    "\n",
    "n_classes = len(class_names)\n",
    "if values.ndim == 1:\n",
    "    phi_pred = values\n",
    "elif values.shape[0] == n_classes:\n",
    "    phi_pred = values[pred_id]\n",
    "elif values.shape[-1] == n_classes:\n",
    "    phi_pred = values[:, pred_id]\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected sv.values shape: {values.shape} (n_classes={n_classes})\")\n",
    "\n",
    "# Base value for the predicted class (logit baseline)\n",
    "base = np.array(sv.base_values[0])\n",
    "if base.ndim == 0:\n",
    "    base_val = float(base)\n",
    "elif base.shape[0] == n_classes:\n",
    "    base_val = float(base[pred_id])\n",
    "else:\n",
    "    base_val = float(np.squeeze(base)[pred_id])\n",
    "\n",
    "# Sanity check: model logit for the predicted class\n",
    "pred_logit = float(predict_logits([TEXT])[0, pred_id].detach().cpu().item())\n",
    "residual = pred_logit - (base_val + float(np.sum(phi_pred)))\n",
    "print(f\"[SHAP] base={base_val:.4f}, sum_phi={np.sum(phi_pred):.4f}, logit={pred_logit:.4f}, residual={residual:+.4f}\")\n",
    "\n",
    "n_feat = min(len(tokens), len(phi_pred))\n",
    "tokens = tokens[:n_feat]\n",
    "phi_pred = np.array(phi_pred[:n_feat]).reshape(-1)\n",
    "\n",
    "#  Bar plot: top-|phi| tokens\n",
    "order = np.argsort(-np.abs(phi_pred))\n",
    "k = min(TOP_K, len(order))\n",
    "order_k = order[:k]\n",
    "\n",
    "top_tokens = [tokens[i] for i in order_k]\n",
    "top_phi = phi_pred[order_k]\n",
    "\n",
    "plt.figure(figsize=(max(8, 0.5 * k), 3))\n",
    "plt.bar(range(k), top_phi)\n",
    "plt.xticks(range(k), top_tokens, rotation=45, ha=\"right\")\n",
    "plt.title(f\"SHAP token attributions — {class_names[pred_id]} (top |φ|)\")\n",
    "plt.tight_layout()\n",
    "fp_bar = os.path.join(OUT_DIR, \"03_shap_tokens_bar.png\")\n",
    "plt.savefig(fp_bar, dpi=150)\n",
    "plt.close()\n",
    "print(\"[saved]\", fp_bar)\n",
    "\n",
    "# Waterfall plot \n",
    "exp_pred = shap.Explanation(\n",
    "    values=phi_pred,\n",
    "    base_values=base_val,\n",
    "    data=tokens\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "shap.plots.waterfall(exp_pred, show=False)\n",
    "plt.tight_layout()\n",
    "fp_wf = os.path.join(OUT_DIR, \"03_shap_waterfall.png\")\n",
    "plt.savefig(fp_wf, dpi=150)\n",
    "plt.close()\n",
    "print(\"[saved]\", fp_wf)\n",
    "\n",
    "#  Decision plot \n",
    "plt.figure(figsize=(8, 3))\n",
    "shap.decision_plot(\n",
    "    base_val,\n",
    "    phi_pred,\n",
    "    feature_names=tokens,\n",
    "    show=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "fp_dec = os.path.join(OUT_DIR, \"03_shap_decision.png\")\n",
    "plt.savefig(fp_dec, dpi=150)\n",
    "plt.close()\n",
    "print(\"[saved]\", fp_dec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 12) LIME — token-level explanation\n",
    "# =======================\n",
    "\n",
    "# Produces:\n",
    "#   - lime_outputs/lime_explanation.html (interactive HTML report)\n",
    "#   - inline notebook visualization via lime_exp.show_in_notebook(text=True)\n",
    "\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "LIME_DIR = os.path.join(OUT_DIR, \"lime_outputs\")\n",
    "os.makedirs(LIME_DIR, exist_ok=True)\n",
    "\n",
    "#  Build the explainer (simple whitespace tokenization)\n",
    "lime_expl = LimeTextExplainer(\n",
    "    class_names=class_names,\n",
    "    mask_string=(tokenizer.mask_token or \"<mask>\"),\n",
    "    split_expression=lambda s: s.split()\n",
    ")\n",
    "\n",
    "#  Explain the predicted class for the current text\n",
    "probs = predict_proba([TEXT])[0]\n",
    "lime_pred = int(np.argmax(probs))\n",
    "\n",
    "lime_exp = lime_expl.explain_instance(\n",
    "    TEXT,\n",
    "    predict_proba,\n",
    "    num_features=12,\n",
    "    num_samples=100, # Reduced to manage memory usage\n",
    "    labels=(lime_pred,)\n",
    ")\n",
    "\n",
    "#  Save interactive HTML report\n",
    "html_path = os.path.join(LIME_DIR, \"lime_explanation.html\")\n",
    "with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(lime_exp.as_html())\n",
    "print(\"[saved]\", html_path)\n",
    "\n",
    "#  Notebook-only visualization (works in Jupyter/Colab)\n",
    "lime_exp.show_in_notebook(text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 13) Logit Lens — layer-wise logits + plot\n",
    "# =======================\n",
    "\n",
    "# What this does:\n",
    "# - Runs the model with `output_hidden_states=True`\n",
    "# - For each hidden state (Emb + each encoder layer), projects the <s> token (index 0) through the\n",
    "#   classification head to get a logit for a chosen target class.\n",
    "\n",
    "@torch.inference_mode()\n",
    "def compute_logit_lens_curve(model, tokenizer, text, target_id=None, max_length=256):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      logits_per_layer: np.ndarray of shape (L+1,) for [Emb, L0, ..., L{L-1}]\n",
    "      target_id: int (tracked class index)\n",
    "      layer_names: list[str]\n",
    "    \"\"\"\n",
    "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length).to(DEVICE)\n",
    "    out = model(**enc, output_hidden_states=True, return_dict=True)\n",
    "\n",
    "    # Choose which class logit to track\n",
    "    final_logits = out.logits[0]  \n",
    "    if target_id is None:\n",
    "        target_id = int(final_logits.argmax().item())\n",
    "\n",
    "    # Locate the classification head\n",
    "    clf = getattr(model, \"classifier\", getattr(model, \"score\", None))\n",
    "    if clf is None:\n",
    "        raise RuntimeError(\"Classifier head not found (expected .classifier or .score).\")\n",
    "\n",
    "    logits_per_layer = []\n",
    "    for H in out.hidden_states:  # list length L+1, each (1, T, D)\n",
    "        h_cls = H[:, 0, :]       # (1, D) token at position 0 (<s>)\n",
    "        if hasattr(clf, \"dense\") and hasattr(clf, \"out_proj\"):\n",
    "            # Deterministic RobertaClassificationHead (dropout removed)\n",
    "            x = torch.tanh(clf.dense(h_cls))\n",
    "            s = clf.out_proj(x) \n",
    "        else:\n",
    "            # Linear-only heads \n",
    "            s = clf(h_cls)\n",
    "        logits_per_layer.append(float(s[0, target_id].item()))\n",
    "\n",
    "    logits_per_layer = np.array(logits_per_layer, dtype=float)\n",
    "    L = len(logits_per_layer) - 1\n",
    "    layer_names = [\"Emb\"] + [f\"L{i}\" for i in range(L)]\n",
    "    return logits_per_layer, target_id, layer_names\n",
    "\n",
    "\n",
    "# ---- Run logit-lens on the current utterance ----\n",
    "target_id = pred_id if \"pred_id\" in globals() else None\n",
    "id2label_local = id2label if \"id2label\" in globals() else getattr(model.config, \"id2label\", None)\n",
    "\n",
    "logits_curve, target_id, layer_names = compute_logit_lens_curve(model, tokenizer, TEXT, target_id=target_id)\n",
    "target_label = id2label_local[target_id] if isinstance(id2label_local, dict) else str(target_id)\n",
    "\n",
    "# Per-utterance z-normalization (helps compare shapes across inputs)\n",
    "z_curve = (logits_curve - logits_curve.mean()) / (logits_curve.std() + 1e-12)\n",
    "\n",
    "print(f\"[Logit-lens] target={target_label} (id={target_id})\")\n",
    "print(\"[Logit-lens] logits per layer:\", np.round(logits_curve, 3))\n",
    "\n",
    "# ---- Plot raw logit + z-logit ----\n",
    "x = np.arange(len(layer_names))\n",
    "\n",
    "plt.figure(figsize=(7.5, 3.2))\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(x, logits_curve, marker=\"o\", label=\"logit\", linewidth=2)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(layer_names)\n",
    "ax1.set_xlabel(\"Layer\")\n",
    "ax1.set_ylabel(f\"logit({target_label})\")\n",
    "ax1.grid(alpha=0.2)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, z_curve, marker=\"s\", linestyle=\"--\", label=\"z-logit\", alpha=0.8)\n",
    "ax2.set_ylabel(\"z-logit (per utterance)\")\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines + lines2, labels + labels2, loc=\"best\")\n",
    "\n",
    "plt.title(f\"Logit-lens per layer — target: {target_label}\")\n",
    "plt.tight_layout()\n",
    "fp = os.path.join(OUT_DIR, \"logit_lens_per_layer.png\")\n",
    "plt.savefig(fp, dpi=150)\n",
    "plt.close()\n",
    "print(\"[saved]\", fp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 15) Optimus — token-level analysis (Baseline A & Prime)\n",
    "# =======================\n",
    "\n",
    "# CONFIG \n",
    "\n",
    "TASK = \"single_label\"               # or \"multi_label\"\n",
    "TEXT = (\" Push! \")\n",
    "\n",
    "# Deps \n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install \"transformers>=4.41\" \"torch>=2.2\" numpy matplotlib\n",
    "# Optional; if it fails, we shim and still run attention-based Optimus:\n",
    "!pip -q install \"transformers-interpret>=0.9.6\" || true\n",
    "\n",
    "# Clone Optimus & set path \n",
    "import os, sys, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "repo_dir = \"/content/optimus_repo\"\n",
    "if not os.path.exists(repo_dir):\n",
    "    !git clone -q https://github.com/intelligence-csd-auth-gr/Optimus-Transformers-Interpretability.git {repo_dir}\n",
    "os.chdir(repo_dir)\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "# ===== 3) Safe shim for transformers_interpret (non-throwing on __init__) =====\n",
    "import sys as _sys, types, importlib\n",
    "# Purge any cached bad shim/import\n",
    "for k in list(_sys.modules):\n",
    "    if k == \"transformers_interpret\" or k.startswith(\"transformers_interpret.\"):\n",
    "        _sys.modules.pop(k, None)\n",
    "try:\n",
    "    import transformers_interpret  # if this works, great\n",
    "except Exception:\n",
    "    class _DummySequenceClassificationExplainer:\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            self.model = args[0] if args else kwargs.get(\"model\", None)\n",
    "            self.tokenizer = kwargs.get(\"tokenizer\", None)\n",
    "        def __call__(self, *a, **k): raise RuntimeError(\"transformers-interpret not available; IG/LIME disabled.\")\n",
    "        def saliency_interpret(self, *a, **k): raise RuntimeError(\"transformers-interpret not available; IG/LIME disabled.\")\n",
    "        def integrated_gradients(self, *a, **k): raise RuntimeError(\"transformers-interpret not available; IG/LIME disabled.\")\n",
    "        def lime(self, *a, **k): raise RuntimeError(\"transformers-interpret not available; IG/LIME disabled.\")\n",
    "    ti = types.ModuleType(\"transformers_interpret\")\n",
    "    ti.SequenceClassificationExplainer = _DummySequenceClassificationExplainer\n",
    "    _sys.modules[\"transformers_interpret\"] = ti\n",
    "\n",
    "#  HF wrapper + trainer shim (what Optimus expects)\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "class _DummyTrainer:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict(self, dataset):\n",
    "        # Try to get raw texts; fallback to decoding\n",
    "        texts = None\n",
    "        for attr in [\"set_of_instance\", \"instances\", \"texts\", \"samples\", \"data\", \"inputs\", \"input_texts\", \"instance\"]:\n",
    "            if hasattr(dataset, attr):\n",
    "                val = getattr(dataset, attr)\n",
    "                if isinstance(val, (list, tuple)): texts = list(val)\n",
    "                elif isinstance(val, str):         texts = [val]\n",
    "                if texts: break\n",
    "        if texts is None and hasattr(dataset, \"__len__\") and hasattr(dataset, \"__getitem__\"):\n",
    "            try:\n",
    "                texts = []\n",
    "                for i in range(len(dataset)):\n",
    "                    item = dataset[i]\n",
    "                    if isinstance(item, (list, tuple)) and item and isinstance(item[0], str):\n",
    "                        texts.append(item[0])\n",
    "                    elif isinstance(item, dict) and \"text\" in item:\n",
    "                        texts.append(item[\"text\"])\n",
    "                    elif isinstance(item, dict) and \"input_ids\" in item:\n",
    "                        ids = item[\"input_ids\"]\n",
    "                        ids = ids.tolist() if hasattr(ids, \"tolist\") else ids\n",
    "                        texts.append(self.tokenizer.decode(ids, skip_special_tokens=True))\n",
    "            except Exception:\n",
    "                pass\n",
    "        if not texts: texts = [\"\"]\n",
    "\n",
    "        logits_list, hidden_list, attn_list = [], [], []\n",
    "        for text in texts:\n",
    "            enc = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=False,\n",
    "                                 add_special_tokens=True, return_attention_mask=True)\n",
    "            enc = {k: v.to(self.device) for k, v in enc.items()}\n",
    "            out = self.model(**enc, output_attentions=True, output_hidden_states=True, return_dict=True)\n",
    "            logits_list.append(out.logits.detach().cpu().numpy())                             \n",
    "            hidden_list.append(np.stack([h.detach().cpu().numpy() for h in out.hidden_states], \n",
    "                                        axis=0))\n",
    "            attn_list.append(np.stack([a.detach().cpu().numpy() for a in out.attentions],        \n",
    "                                       axis=0))\n",
    "\n",
    "        logits = np.concatenate(logits_list, axis=0)                                 \n",
    "        hidden = np.concatenate(hidden_list, axis=1) if len(hidden_list)>1 else hidden_list[0]\n",
    "        attns  = np.concatenate(attn_list,  axis=1) if len(attn_list)>1  else attn_list[0]\n",
    "        return SimpleNamespace(predictions=(logits, hidden, attns))\n",
    "\n",
    "class HFModelWrapper:\n",
    "    def __init__(self, model_id=MODEL_ID, task=TASK, device=None):\n",
    "        self.id = model_id\n",
    "        self.task = task\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", use_fast=True)\n",
    "        self._hf_model = AutoModelForSequenceClassification.from_pretrained(self.id, output_attentions=True).to(self.device).eval()\n",
    "        self.trainer = _DummyTrainer(self._hf_model, self.tokenizer)\n",
    "        self.num_labels = self._hf_model.config.num_labels\n",
    "        self.label_names = [self._hf_model.config.id2label[i] for i in range(self.num_labels)]\n",
    "        self.bos_token = self.tokenizer.bos_token or \"<s>\"\n",
    "        self.eos_token = self.tokenizer.eos_token or \"</s>\"\n",
    "        self.pad_tokens = {\"<pad>\", \"[PAD]\"}\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict_proba(self, text: str):\n",
    "        enc = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=False,\n",
    "                             add_special_tokens=True, return_attention_mask=True)\n",
    "        enc = {k: v.to(self.device) for k, v in enc.items()}\n",
    "        out = self._hf_model(**enc, output_attentions=True, output_hidden_states=True, return_dict=True)\n",
    "        if self.task == \"multi_label\":\n",
    "            return torch.sigmoid(out.logits).detach().cpu().numpy()[0]\n",
    "        return torch.softmax(out.logits, dim=-1).detach().cpu().numpy()[0]\n",
    "\n",
    "# Import Optimus & load model \n",
    "import optimus; importlib.reload(optimus)  # ensure it sees our shim\n",
    "from optimus import Optimus, plot_text_heatmap, plot_sentence_heatmap\n",
    "\n",
    "wrapper = HFModelWrapper(MODEL_ID, TASK)\n",
    "label_names = wrapper.label_names\n",
    "\n",
    "# Small calibration pool\n",
    "calib = [\n",
    "    \"I feel incredibly happy today!\",\n",
    "    \"This makes me anxious and a bit afraid.\",\n",
    "    \"I'm grateful for your help.\",\n",
    "    \"I am angry about the delay.\",\n",
    "]\n",
    "ionbot = Optimus(wrapper, wrapper.tokenizer, label_names, task=TASK, set_of_instance=calib)\n",
    "\n",
    "#  Explain (Baseline & Prime) \n",
    "\n",
    "# token-level\n",
    "scores_tok_b, toks_b = ionbot.explain(TEXT, mode=\"baseline\",         level=\"token\",    raw_attention=\"A\")\n",
    "scores_tok_p, toks_p = ionbot.explain(TEXT, mode=\"max_per_instance\", level=\"token\",    raw_attention=\"A\")\n",
    "\n",
    "\n",
    "\n",
    "# Utilities to make RoBERTa tokens pretty & safe \n",
    "SPECIALS = {wrapper.bos_token, wrapper.eos_token} | wrapper.pad_tokens\n",
    "\n",
    "def roberta_pretty_tokens(tokens):\n",
    "    \"\"\"Remove RoBERTa space mark (Ġ) and map BOS/EOS to readable tags.\"\"\"\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        if t == wrapper.bos_token: out.append(\"[CLS]\"); continue\n",
    "        if t == wrapper.eos_token: out.append(\"[SEP]\"); continue\n",
    "        out.append(t.replace(\"Ġ\", \"\"))  # drop space marker; plot lib handles spacing per token\n",
    "    return out\n",
    "\n",
    "def strip_specials_align(tokens, scores_2d):\n",
    "    \"\"\"Cast to NumPy, align lengths, drop specials if any remain.\"\"\"\n",
    "    arr = np.asarray(scores_2d, dtype=float)\n",
    "    T = min(arr.shape[1], len(tokens))\n",
    "    toks = list(tokens)[:T]\n",
    "    arr  = arr[:, :T]\n",
    "    keep = [i for i, t in enumerate(toks) if t not in SPECIALS]\n",
    "    if keep:  # only drop if something remains; else keep all to avoid empties\n",
    "        toks = [toks[i] for i in keep]\n",
    "        arr  = arr[:, keep]\n",
    "    return toks, arr\n",
    "\n",
    "# Preprocess for plotting (Baseline/Prime tokens handled separately, then aligned if needed)\n",
    "toks_b_pp = roberta_pretty_tokens(toks_b)\n",
    "toks_p_pp = roberta_pretty_tokens(toks_p)\n",
    "toks_b_pp, scores_tok_b = strip_specials_align(toks_b_pp, scores_tok_b)\n",
    "toks_p_pp, scores_tok_p = strip_specials_align(toks_p_pp, scores_tok_p)\n",
    "\n",
    "# ===== 8) Pick top label and plot (built-in heatmaps only) =====\n",
    "probs = wrapper.predict_proba(TEXT)\n",
    "pred_idx = int(np.argmax(probs))\n",
    "pred_label = label_names[pred_idx]\n",
    "print(\"Top label:\", pred_label, \"| probs:\", dict(zip(label_names, np.round(probs, 3))))\n",
    "\n",
    "# Token heatmaps (Baseline & Prime) — predicted label only\n",
    "plot_text_heatmap(toks_b_pp, scores_tok_b[pred_idx])\n",
    "plt.title(f\"Baseline (A) — tokens — {pred_label}\")\n",
    "plt.show()\n",
    "\n",
    "# Align token lengths for Prime if they differ (use the shorter)\n",
    "T = min(len(toks_b_pp), len(toks_p_pp), scores_tok_b.shape[1], scores_tok_p.shape[1])\n",
    "plot_text_heatmap(toks_p_pp[:T], scores_tok_p[pred_idx, :T])\n",
    "plt.title(f\"Optimus Prime — tokens — {pred_label}\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0158bb86b679483590afdabbab8fab87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0856bb08bd334d70a7e279619d1ce7d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0acfb2749d804d78849dab32e71a1b03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c8af3ed5f2b4d449d8b227d9305818b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67a149d282254895bcabeb03cf39aec8",
      "placeholder": "​",
      "style": "IPY_MODEL_c63a073ca24541f49bb23892b1af4a4d",
      "value": "vocab.json: 100%"
     }
    },
    "10d08fc4177e453a99f12f1fdb9810dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_139de5e9ab4a4c47aeafc25b289297a9",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0e3adbcf25d4bd3b305df8b4accdc08",
      "value": 1355863
     }
    },
    "139de5e9ab4a4c47aeafc25b289297a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22407f2d9c4e4311a22d515bf0aae16c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a495a4c82e34ded8ca910fc8bef93fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0856bb08bd334d70a7e279619d1ce7d6",
      "placeholder": "​",
      "style": "IPY_MODEL_53f2c9810b4647928e57d5fddb764c92",
      "value": " 456k/456k [00:00&lt;00:00, 10.6MB/s]"
     }
    },
    "2da9b7778c7e4a9d854c96ee3b99f67e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "342c549f504c44edaf2b775af5984f7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7151a8eecc4d4bc392efd87565387e8f",
      "placeholder": "​",
      "style": "IPY_MODEL_80e59334cb4340c1b173c54ce36fe58a",
      "value": "merges.txt: 100%"
     }
    },
    "37a5736153f34acc96f87ca6af8786d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92346883034b4d2dac7226e75b30b5bb",
       "IPY_MODEL_10d08fc4177e453a99f12f1fdb9810dd",
       "IPY_MODEL_5eca207b22e3489d8d3d2d4590ded221"
      ],
      "layout": "IPY_MODEL_cf1430919be349d48728729f148e4d3d"
     }
    },
    "47562661474e438e907eab8d9e7949c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0c8af3ed5f2b4d449d8b227d9305818b",
       "IPY_MODEL_8c366be4dcd24bb986695f7ccefa3194",
       "IPY_MODEL_c4013c98c5bc4a598a4f4e75b6ca2c26"
      ],
      "layout": "IPY_MODEL_6231388a587a4feda782e76476e55ff1"
     }
    },
    "49b1db37b86d42e3916c3a46592e8d3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49b7ddb71d944e9b957057a0e436b87a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e91857146f640ae80c1118f798bad10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53323795ce3f406f86f5b54c10e0dd36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2da9b7778c7e4a9d854c96ee3b99f67e",
      "placeholder": "​",
      "style": "IPY_MODEL_e10fc4d9947249939f90e1728ac6cdca",
      "value": "config.json: 100%"
     }
    },
    "53f2c9810b4647928e57d5fddb764c92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "588da162f50d497992f4fb00a5955462": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0acfb2749d804d78849dab32e71a1b03",
      "placeholder": "​",
      "style": "IPY_MODEL_8805e18068a34018bf83b5e0805b385d",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "58b42b67e99640e89863e5ef517c2617": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0158bb86b679483590afdabbab8fab87",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c910b00f73554d09a1230fd718c28006",
      "value": 25
     }
    },
    "58e68c161e0340bb8e6a3fbb58fdb011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49b7ddb71d944e9b957057a0e436b87a",
      "placeholder": "​",
      "style": "IPY_MODEL_bf6c39a0c7af4a608803f22bb8258e84",
      "value": " 25.0/25.0 [00:00&lt;00:00, 1.16kB/s]"
     }
    },
    "5eca207b22e3489d8d3d2d4590ded221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e91857146f640ae80c1118f798bad10",
      "placeholder": "​",
      "style": "IPY_MODEL_88cbd43c112d4795885e738a01d226fa",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 21.8MB/s]"
     }
    },
    "6231388a587a4feda782e76476e55ff1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67a149d282254895bcabeb03cf39aec8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d5249c784c940d69f275df5c00faffe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d7d5bae27ca420aa37b4994734b0801": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7151a8eecc4d4bc392efd87565387e8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74d06f68ce0e4663887f3d4a615f8f3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fb5d2016bb94a8a8f58f04d14626059": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80e59334cb4340c1b173c54ce36fe58a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8273e020448b42d1beb960a780a8c527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ca3d745781846f6819f9fd6eb052f4f",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e353d615672549d3b69bd1ee0a96669b",
      "value": 481
     }
    },
    "8805e18068a34018bf83b5e0805b385d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88cbd43c112d4795885e738a01d226fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c366be4dcd24bb986695f7ccefa3194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d5249c784c940d69f275df5c00faffe",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7df0c715cc5463bb4614597a9434fd6",
      "value": 898823
     }
    },
    "8ca3d745781846f6819f9fd6eb052f4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92346883034b4d2dac7226e75b30b5bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6f0e98b85fa4df99370990054a89f64",
      "placeholder": "​",
      "style": "IPY_MODEL_74d06f68ce0e4663887f3d4a615f8f3f",
      "value": "tokenizer.json: 100%"
     }
    },
    "929c99439a4d4fe28ca10035c7ccd8cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49b1db37b86d42e3916c3a46592e8d3f",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7d6a8ccd3f6431896d78921b10f430e",
      "value": 456318
     }
    },
    "b0e3adbcf25d4bd3b305df8b4accdc08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf6c39a0c7af4a608803f22bb8258e84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4013c98c5bc4a598a4f4e75b6ca2c26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5cfa8a9d5994ac582fe043705405b9c",
      "placeholder": "​",
      "style": "IPY_MODEL_22407f2d9c4e4311a22d515bf0aae16c",
      "value": " 899k/899k [00:00&lt;00:00, 3.09MB/s]"
     }
    },
    "c63a073ca24541f49bb23892b1af4a4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c910b00f73554d09a1230fd718c28006": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ca06578cc86647bba34b5af2a3375b14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf1430919be349d48728729f148e4d3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d36ee96241bb417386456d1fd0d13346": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef9d6f2cee7742db900b368e8939619b",
      "placeholder": "​",
      "style": "IPY_MODEL_7fb5d2016bb94a8a8f58f04d14626059",
      "value": " 481/481 [00:00&lt;00:00, 17.2kB/s]"
     }
    },
    "d6f0e98b85fa4df99370990054a89f64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7d6a8ccd3f6431896d78921b10f430e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d7df0c715cc5463bb4614597a9434fd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dda6b2659cf34b2f851f10626aa30324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_342c549f504c44edaf2b775af5984f7b",
       "IPY_MODEL_929c99439a4d4fe28ca10035c7ccd8cb",
       "IPY_MODEL_2a495a4c82e34ded8ca910fc8bef93fe"
      ],
      "layout": "IPY_MODEL_e9330009045043b18c707bce7166b389"
     }
    },
    "e10fc4d9947249939f90e1728ac6cdca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e353d615672549d3b69bd1ee0a96669b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e5cfa8a9d5994ac582fe043705405b9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7da4e02ef914351a4983a4c07aa92f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53323795ce3f406f86f5b54c10e0dd36",
       "IPY_MODEL_8273e020448b42d1beb960a780a8c527",
       "IPY_MODEL_d36ee96241bb417386456d1fd0d13346"
      ],
      "layout": "IPY_MODEL_ca06578cc86647bba34b5af2a3375b14"
     }
    },
    "e9330009045043b18c707bce7166b389": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef9d6f2cee7742db900b368e8939619b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9c9b4c044bb45288e84d9b88f22afb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_588da162f50d497992f4fb00a5955462",
       "IPY_MODEL_58b42b67e99640e89863e5ef517c2617",
       "IPY_MODEL_58e68c161e0340bb8e6a3fbb58fdb011"
      ],
      "layout": "IPY_MODEL_6d7d5bae27ca420aa37b4994734b0801"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
